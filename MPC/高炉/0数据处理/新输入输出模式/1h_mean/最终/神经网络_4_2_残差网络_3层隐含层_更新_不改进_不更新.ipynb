{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 库文件\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import gp_minimize\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "# 设置中文字体\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=12)  # 替换为你的中文字体文件路径\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\haokw\\Documents\\GitHub\\gaolu\\MPC\\高炉\")\n",
    "\n",
    "\n",
    "import base \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "excel_path = f'C:\\\\Users\\\\haokw\\\\Documents\\\\GitHub\\\\gaolu\\\\MPC\\\\高炉\\\\0数据处理\\\\新输入输出模式\\\\1h_mean.xlsx'\n",
    "df_sheet_yuansu = pd.read_excel(excel_path, sheet_name='原始输出') \n",
    "# df_sheet_yuansu = pd.read_excel(excel_path, sheet_name='剔除直线输出') \n",
    "# df_sheet_yuansu = pd.read_excel(excel_path, sheet_name='单SI_0.2_0.8') \n",
    "# print(df_sheet_yuansu.info())\n",
    "# print(df_sheet_yuansu.columns)\n",
    "\n",
    "excel_path = f'C:\\\\Users\\\\haokw\\\\Documents\\\\GitHub\\\\gaolu\\\\MPC\\\\高炉\\\\0数据处理\\\\新输入输出模式\\\\1h_mean.xlsx'\n",
    "df_sheet_params = pd.read_excel(excel_path, sheet_name='1h_mean_all') \n",
    "\n",
    "# print(df_sheet_params.info())\n",
    "# print(df_sheet_params.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 df 是你的 DataFrame\n",
    "\n",
    "# 检查 DataFrame 中是否包含 NaN 值\n",
    "contains_nan = df_sheet_yuansu.isna().any().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"数据包含 NaN 值\")\n",
    "else:\n",
    "    print(\"数据不包含 NaN 值\")\n",
    "    # 检查 DataFrame 中是否包含 NaN 值\n",
    "contains_nan = df_sheet_params.isna().any().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"数据包含 NaN 值\")\n",
    "else:\n",
    "    print(\"数据不包含 NaN 值\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入输出参数     '富氧流量', '冷风流量', '热风压力', '冷风压力', '热风温度', '鼓风湿度', '设定喷煤量'\n",
    "input_term =        ['富氧流量', '设定喷煤量', '热风压力', '热风温度']\n",
    "output_term = ['铁水温度[MIT]', '铁水硅含量[SI]']\n",
    "time_term= '时间戳h'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常数据处理-处理前后对比\n",
    "# 创建数据框副本以避免修改原始数据\n",
    "df_sheet_yuansu_process = df_sheet_yuansu.copy()\n",
    "df_sheet_params_process = df_sheet_params.copy()\n",
    "# 定义一个函数，用前后两个值的差值按照距离进行加权替换异常值\n",
    "def replace_outliers_with_weighted_diff(x, y):\n",
    "    # 计算列的中位数\n",
    "    median_value = y.median()\n",
    "    # 检测异常值的索引\n",
    "    outliers_index = (y - median_value).abs() > 2.5 * y.std()\n",
    "    \n",
    "    # 遍历异常值的索引\n",
    "    for idx in outliers_index[outliers_index].index:\n",
    "        # 获取异常值前一个和后一个值的索引\n",
    "        prev_idx = idx - 1 if idx - 1 >= 0 else idx\n",
    "        next_idx = idx + 1 if idx + 1 < len(y) else idx\n",
    "        # 计算当前 x 与前后两个 x 的距离\n",
    "        dist_prev = abs(x[idx] - x[prev_idx])\n",
    "        dist_next = abs(x[next_idx] - x[idx])\n",
    "        total_dist = dist_prev + dist_next\n",
    "        # 计算权重\n",
    "        weight_prev = dist_next / total_dist\n",
    "        weight_next = dist_prev / total_dist\n",
    "        # 计算前后两个值的差值\n",
    "        diff = y[next_idx] - y[prev_idx]\n",
    "        # 根据权重进行插值\n",
    "        interpolated_value = y[prev_idx] + weight_prev * diff\n",
    "        # 用插值结果替代异常值\n",
    "        y[idx] = interpolated_value\n",
    "\n",
    "# 画出数据\n",
    "def plot_subplot(data_x,data_y_yuan,data_y,column):\n",
    "    plt.plot(data_x,data_y_yuan,'r-')\n",
    "    plt.plot(data_x,data_y,'m-')\n",
    "    # plt.xlabel(time_term, fontproperties=font)  # 使用中文标签\n",
    "    plt.ylabel(column, fontproperties=font)  # 使用中文标签\n",
    "    # 使用中文标签\n",
    "\n",
    "\n",
    "# 对指定列应用替代异常值的函数\n",
    "# 对指定列应用替代异常值的函数\n",
    "replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[0]])\n",
    "replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[1]])\n",
    "replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[2]])\n",
    "replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[3]])\n",
    "# replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[4]])\n",
    "# replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[5]])\n",
    "# replace_outliers_with_weighted_diff(df_sheet_params_process[time_term], df_sheet_params_process[input_term[6]])\n",
    "\n",
    "# replace_outliers_with_weighted_diff(df_sheet_yuansu_process[time_term], df_sheet_yuansu_process[output_term[0]])\n",
    "# replace_outliers_with_weighted_diff(df_sheet_yuansu_process[time_term], df_sheet_yuansu_process[output_term[1]])\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "for idx, column in enumerate(input_term):\n",
    "    plt.subplot(len(input_term), 1, idx+1)\n",
    "    plot_subplot(df_sheet_params_process[time_term].values,df_sheet_params[column].values,df_sheet_params_process[column].values,column)\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "for idx, column in enumerate(output_term):\n",
    "    plt.subplot(len(output_term), 1, idx+1)\n",
    "    plot_subplot(df_sheet_yuansu_process[time_term].values,df_sheet_yuansu[column].values,df_sheet_yuansu_process[column].values,column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出选取的数据\n",
    "def plot_subplot(data_x,data_y,column,index_predict,index_gaolu):\n",
    "    plt.plot(data_x,data_y,'-', label='origin_data')\n",
    "    plt.plot(data_x[index_gaolu],data_y[index_gaolu],'r.', label='gaolu_data')\n",
    "    plt.plot(data_x[index_predict],data_y[index_predict],'g-', label='predict_data')\n",
    "    plt.legend()\n",
    "    # plt.xlabel(time_term, fontproperties=font)  # 使用中文标签\n",
    "    plt.ylabel(column, fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "\n",
    "length1 = 400\n",
    "start1 = 0\n",
    "length2 = 400\n",
    "start2 = 400\n",
    "\n",
    "\n",
    "index_gaolu   = range(start1, start1+length1+1, 1)\n",
    "index_predict     = range(start2, start2+length2+1, 1)\n",
    "# index = range(1, 7572, 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for idx, column in enumerate(output_term):\n",
    "    plt.subplot(len(input_term+output_term), 1, idx+1)\n",
    "    plot_subplot(df_sheet_yuansu_process[time_term].values,df_sheet_yuansu_process[column].values,column,index_predict,index_gaolu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化、逆归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 将数据存储为字典，每个键对应一列数据\n",
    "original_data_dict = {\n",
    "    input_term[0]:   df_sheet_params_process[input_term[0]].values,\n",
    "    input_term[1]:   df_sheet_params_process[input_term[1]].values,\n",
    "    input_term[2]:   df_sheet_params_process[input_term[2]].values,\n",
    "    input_term[3]:   df_sheet_params_process[input_term[3]].values,\n",
    "    # input_term[4]:   df_sheet_params_process[input_term[4]].values,\n",
    "    # input_term[5]:   df_sheet_params_process[input_term[5]].values,\n",
    "    # input_term[6]:   df_sheet_params_process[input_term[6]].values,\n",
    "    output_term[0]:  df_sheet_yuansu_process[output_term[0]].values,\n",
    "    output_term[1]:  df_sheet_yuansu_process[output_term[1]].values\n",
    "}\n",
    "\n",
    "# 初始化缩放器\n",
    "scalers = {}\n",
    "\n",
    "# 进行拟合\n",
    "for column, data in original_data_dict.items():\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler.fit(data.reshape(-1, 1))  # 保证数据是列向量\n",
    "    scalers[column] = scaler\n",
    "\n",
    "# 进行归一化\n",
    "normalized_data_dict = {}\n",
    "for column, scaler in scalers.items():\n",
    "    normalized_data_dict[column] = scaler.transform(original_data_dict[column].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 进行反归一化\n",
    "original_data_dict = {}\n",
    "for column, scaler in scalers.items():\n",
    "    original_data_dict[column] = scaler.inverse_transform(normalized_data_dict[column].reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标定归一化前后数据\n",
    "data_point = np.array([1500]).reshape(-1, 1)\n",
    "data1 = scalers[output_term[0]].transform(data_point).flatten()\n",
    "\n",
    "data_point = np.array(data1).reshape(-1, 1)\n",
    "data2 = scalers[output_term[0]].inverse_transform(data_point).flatten()\n",
    "\n",
    "data_point = np.array([1510]).reshape(-1, 1)\n",
    "data3 = scalers[output_term[0]].transform(data_point).flatten()\n",
    "\n",
    "data_point = np.array(data3).reshape(-1, 1)\n",
    "data4 = scalers[output_term[0]].inverse_transform(data_point).flatten()\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "print(data3)\n",
    "print(data4)\n",
    "d_temp = (data3-data1)/(data4-data2)\n",
    "print('每摄氏度的输出差：',d_temp)\n",
    "\n",
    "\n",
    "\n",
    "data_point = np.array([0.50]).reshape(-1, 1)\n",
    "data1 = scalers[output_term[1]].transform(data_point).flatten()\n",
    "\n",
    "data_point = np.array(data1).reshape(-1, 1)\n",
    "data2 = scalers[output_term[1]].inverse_transform(data_point).flatten()\n",
    "\n",
    "data_point = np.array([0.60]).reshape(-1, 1)\n",
    "data3 = scalers[output_term[1]].transform(data_point).flatten()\n",
    "\n",
    "data_point = np.array(data3).reshape(-1, 1)\n",
    "data4 = scalers[output_term[1]].inverse_transform(data_point).flatten()\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "print(data3)\n",
    "print(data4)\n",
    "d_yuansu = (data3-data1)/(data4-data2)\n",
    "print('每浓度的输出差：',(data3-data1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isShuffle = True\n",
    "isShuffle = False\n",
    "time_steps = 2\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "train_size = 1-val_size-test_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合训练数据--拆分训练、测试集\n",
    "\n",
    "# 定义时间步数和特征数\n",
    "\n",
    "# 构成    \n",
    "# X = [X(t),X(t-1),Y(t-1)]\n",
    "# Y = [Y(t)]\n",
    "def make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,index_fanwei):\n",
    "    X = np.column_stack((u1_data,u2_data,u3_data,u4_data))\n",
    "    y = np.column_stack((y1_data, y2_data))\n",
    "\n",
    "    X_modified = []\n",
    "    y_modified = []\n",
    "    \n",
    "    for i in range(3,len(y1_data)):\n",
    "        if i in index_fanwei:\n",
    "            # print(i)\n",
    "            # print(df_sheet_yuansu[time_term][i])\n",
    "            yuansu_time = df_sheet_yuansu[time_term][i]\n",
    "            closest_10 = df_sheet_params[df_sheet_params[time_term] <= yuansu_time].nlargest(time_steps, time_term)\n",
    "            # print(closest_10)\n",
    "            \n",
    "            index = closest_10.index\n",
    "            # print(index)\n",
    "            # print(closest_10.iloc[-1][time_term])\n",
    "            if closest_10.iloc[-1][time_term] < yuansu_time - time_steps + 1:\n",
    "                print(i,yuansu_time,'errloss')\n",
    "            else:\n",
    "\n",
    "                # print(X[index, :])\n",
    "                new_x_sample = np.concatenate([X[i, :] for i in index],axis=0)\n",
    "                # print(new_x_sample)\n",
    "                y_last = y[i-1, :]\n",
    "                # print(y_last, 'y_last time : ',df_sheet_yuansu[time_term][i-1])\n",
    "                new_x_sample = np.concatenate([new_x_sample,y_last],axis=0)\n",
    "                # print(new_x_sample)\n",
    "                y_sample = y[i, :]  \n",
    "                X_modified.append(new_x_sample)\n",
    "                y_modified.append(y_sample)\n",
    "                print(i,yuansu_time,index[0],index[-1], end='\\r')\n",
    "                # break\n",
    "\n",
    "    # 将列表转换为 NumPy 数组\n",
    "    X_modified = np.array(X_modified)\n",
    "    y_modified = np.array(y_modified)\n",
    "    X_reshaped = X_modified.reshape((X_modified.shape[0], X_modified.shape[1]))\n",
    "\n",
    "    # 打印新数据的形状\n",
    "    print(\"Modified Input Shape:\", X_reshaped.shape)\n",
    "    print(\"Modified Output Shape:\", y_modified.shape)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_modified, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=42, \n",
    "                                                        shuffle=isShuffle)\n",
    "\n",
    "    # 将剩余的70%训练数据再次拆分成训练数据和验证数据（20%验证数据，50%训练数据）\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                        test_size=val_size/(train_size+val_size), \n",
    "                                                        random_state=42, \n",
    "                                                        shuffle=isShuffle)\n",
    "\n",
    "    print('训练数量：',X_train.shape,y_train.shape)\n",
    "    print('验证数量：',X_val.shape,y_val.shape)\n",
    "    print('测试数量：',X_test.shape,y_test.shape)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetrical_moving_average(data, N):\n",
    "    \"\"\"\n",
    "    使用对称的移动平均滤波，当前值由其自身及其前后的值决定。\n",
    "    \n",
    "    :param data: 输入的数据序列，一般为列表或者NumPy数组。\n",
    "    :return: 经过滤波处理的数据序列。\n",
    "    \"\"\"\n",
    "    filtered_data = []\n",
    "    N = 9\n",
    "    percent = 0.8\n",
    "    # 遍历数据，从索引1开始到倒数第二个元素结束\n",
    "    for i in range(1, len(data) - 1):\n",
    "        # 计算当前值及其前后值的平均\n",
    "        average = (data[i - 1]*(1-percent)/2 + data[i]*percent + data[i + 1]*(1-percent)/2)\n",
    "        filtered_data.append(average)\n",
    "    \n",
    "    # 对于序列的第一个和最后一个元素，直接使用原始值\n",
    "    # 或者可以使用其他边界处理策略\n",
    "    filtered_data.insert(0, data[0])\n",
    "    filtered_data.append(data[-1])\n",
    "    \n",
    "    return np.array(filtered_data)\n",
    "\n",
    "# 示例数据\n",
    "data = [2, 4, 6, 8, 10, 12, 14]\n",
    "filtered_data = symmetrical_moving_average(data,9)\n",
    "print(filtered_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型列数据\n",
    "u1_data = normalized_data_dict[input_term[0]]\n",
    "u2_data = normalized_data_dict[input_term[1]]\n",
    "u3_data = normalized_data_dict[input_term[2]]\n",
    "u4_data = normalized_data_dict[input_term[3]]\n",
    "y1_data = normalized_data_dict[output_term[0]]\n",
    "y2_data = normalized_data_dict[output_term[1]]\n",
    "num_samples = y2_data.shape[0]\n",
    "\n",
    "# filter_windows = 2\n",
    "# u1_data = symmetrical_moving_average(u1_data, filter_windows)\n",
    "# u2_data = symmetrical_moving_average(u2_data, filter_windows)\n",
    "# u3_data = symmetrical_moving_average(u3_data, filter_windows)\n",
    "# u4_data = symmetrical_moving_average(u4_data, filter_windows)\n",
    "# u5_data = symmetrical_moving_average(u5_data, filter_windows)\n",
    "# u6_data = symmetrical_moving_average(u6_data, filter_windows)\n",
    "# u7_data = symmetrical_moving_average(u7_data, filter_windows)\n",
    "# y1_data = symmetrical_moving_average(y1_data, filter_windows)\n",
    "# y2_data = symmetrical_moving_average(y2_data, filter_windows)\n",
    "\n",
    "print('高炉模型数据')\n",
    "X_gaolu_train, X_gaolu_val, X_gaolu_test,\\\n",
    "y_gaolu_train, y_gaolu_val, y_gaolu_test = make_data(u1_data,u2_data,u3_data,u4_data,\n",
    "                                                            y1_data,y2_data,\n",
    "                                                            index_fanwei=index_gaolu)\n",
    "\n",
    "\n",
    "\n",
    "# 预测模型列数据\n",
    "u1_data = normalized_data_dict[input_term[0]]\n",
    "u2_data = normalized_data_dict[input_term[1]]\n",
    "u3_data = normalized_data_dict[input_term[2]]\n",
    "u4_data = normalized_data_dict[input_term[3]]\n",
    "y1_data = normalized_data_dict[output_term[0]]\n",
    "y2_data = normalized_data_dict[output_term[1]]\n",
    "num_samples = y2_data.shape[0]\n",
    "\n",
    "# filter_windows = 2\n",
    "# u1_data = symmetrical_moving_average(u1_data, filter_windows)\n",
    "# u2_data = symmetrical_moving_average(u2_data, filter_windows)\n",
    "# u3_data = symmetrical_moving_average(u3_data, filter_windows)\n",
    "# u4_data = symmetrical_moving_average(u4_data, filter_windows)\n",
    "# u5_data = symmetrical_moving_average(u5_data, filter_windows)\n",
    "# u6_data = symmetrical_moving_average(u6_data, filter_windows)\n",
    "# u7_data = symmetrical_moving_average(u7_data, filter_windows)\n",
    "# y1_data = symmetrical_moving_average(y1_data, filter_windows)\n",
    "# y2_data = symmetrical_moving_average(y2_data, filter_windows)\n",
    "print('预测模型数据')\n",
    "X_predict_train, X_predict_val, X_predict_test,\\\n",
    "y_predict_train, y_predict_val, y_predict_test = make_data(u1_data,u2_data,u3_data,u4_data,\n",
    "                                                            y1_data,y2_data,\n",
    "                                                            index_fanwei=index_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_once_time = 50\n",
    "ischuangxin = True\n",
    "ischuangxin = False\n",
    "cengshu = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, if_chuangxin = False,gamma = 0.1):\n",
    "        self.if_chuangxin = if_chuangxin\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        if cengshu == 3:    \n",
    "            if self.if_chuangxin:            \n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "            else:\n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "                self.relu = nn.ReLU()\n",
    "        elif cengshu == 2:  \n",
    "            if self.if_chuangxin:            \n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "            else:\n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "                self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        if cengshu == 3:    \n",
    "            if self.if_chuangxin:\n",
    "\n",
    "                x = self.fc1(x0)\n",
    "                x = self.relu(x)\n",
    "\n",
    "                x2 = self.fc2(x)\n",
    "                x2 = self.relu(x2)\n",
    "\n",
    "                x3 = self.fc3(x2)\n",
    "                x3 = self.relu(x3)\n",
    "\n",
    "                x4 = x + x2 + x3\n",
    "                output = self.fc4(x4)\n",
    "            else:\n",
    "                x = self.fc1(x0)\n",
    "                x = self.relu(x)\n",
    "\n",
    "                x2 = self.fc2(x)\n",
    "                x2 = self.relu(x2)\n",
    "\n",
    "                x3 = self.fc3(x2)\n",
    "                x3 = self.relu(x3)\n",
    "\n",
    "                output = self.fc4(x3)\n",
    "        elif cengshu == 2:  \n",
    "            if self.if_chuangxin:\n",
    "\n",
    "                x = self.fc1(x0)\n",
    "                x = self.relu(x)\n",
    "\n",
    "                x2 = self.fc2(x)\n",
    "                x2 = self.relu(x2)\n",
    "\n",
    "                x3 = x + x2\n",
    "                output = self.fc3(x3)\n",
    "            else:\n",
    "                x = self.fc1(x0)\n",
    "                x = self.relu(x)\n",
    "\n",
    "                x2 = self.fc2(x)\n",
    "                x2 = self.relu(x2)\n",
    "\n",
    "                output = self.fc3(x2)\n",
    "        return output\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "\n",
    "        squared_diff = torch.pow(y_true - y_pred, 2)\n",
    "        sum_squared_diff = torch.sum(squared_diff)\n",
    "        mse = sum_squared_diff / len(y_true)\n",
    "        return mse\n",
    "    \n",
    "\n",
    "    def my_fit(self, \n",
    "                X_train, y_train, \n",
    "                X_val, y_val, \n",
    "                train_loss_list,val_loss_list,\n",
    "                epochs=1, batch_size=32, lr=0.001):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                x_batch = torch.tensor(X_train[i:i+batch_size], dtype=torch.float32)\n",
    "                y_batch = torch.tensor(y_train[i:i+batch_size], dtype=torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(x_batch)\n",
    "                loss = self.custom_loss(y_batch, y_pred)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            average_epoch_train_loss = epoch_loss / (len(X_train) / batch_size)\n",
    "            # 验证集评估\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for i in range(0, len(X_val), batch_size):\n",
    "                    x_batch_val = torch.tensor(X_val[i:i+batch_size], dtype=torch.float32)\n",
    "                    y_batch_val = torch.tensor(y_val[i:i+batch_size], dtype=torch.float32)\n",
    "\n",
    "                    y_pred_val = self(x_batch_val)\n",
    "                    val_loss += self.custom_loss(y_batch_val, y_pred_val).item()\n",
    "\n",
    "                average_epoch_val_loss = val_loss / (len(X_val) / batch_size)\n",
    "\n",
    "            print(f'第 {epoch + 1}/{epochs} 轮, 训练误差: {average_epoch_train_loss:.4f}, 验证误差: {average_epoch_val_loss:.4f}', end='\\r')\n",
    "            train_loss_list.append(average_epoch_train_loss)\n",
    "            val_loss_list.append(average_epoch_val_loss)\n",
    "\n",
    "        return train_loss_list,val_loss_list\n",
    "    \n",
    "    def model_update(self, \n",
    "                X_train, y_train, \n",
    "                epochs=1, batch_size=32, lr=0.001):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                x_batch = torch.tensor(X_train[i:i+batch_size], dtype=torch.float32)\n",
    "                y_batch = torch.tensor(y_train[i:i+batch_size], dtype=torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(x_batch)\n",
    "                loss = self.custom_loss(y_batch, y_pred)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            average_epoch_train_loss = epoch_loss / (len(X_train) / batch_size)\n",
    "            print(f'第 {epoch + 1}/{epochs} 轮, 训练误差: {average_epoch_train_loss:.4f}')\n",
    "            \n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    \n",
    "\n",
    "    def my_predict(self, X_test):\n",
    "        # 设置模型为评估模式，这会关闭 dropout 等层\n",
    "        self.eval()\n",
    "        # 将输入数据转换为张量，并设置 requires_grad=True\n",
    "        x_tensor = torch.tensor(X_test, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        # 获取模型的预测输出\n",
    "        y_pred = self(x_tensor)\n",
    "        # 保留预测值的梯度信息\n",
    "        y_pred.retain_grad()\n",
    "        # 返回预测结果和包含梯度信息的张量\n",
    "        return y_pred[:,0].detach().numpy(),y_pred[:,1].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立高炉模型实例\n",
    "input_size = 10  # 输入特征大小\n",
    "hidden_size = 16  # 32\n",
    "output_size = 2  # 输出大小\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "model_gaolu = MyNeuralNetwork(input_size, \n",
    "                            hidden_size,\n",
    "                            output_size,\n",
    "                            ischuangxin,\n",
    "                            gamma = 0.1)\n",
    "epoch_sum_gaolu = 0\n",
    "gaolu_train_loss_list = []\n",
    "gaolu_val_loss_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型训练\n",
    "epoch_once = epoch_once_time\n",
    "epoch_sum_gaolu = epoch_sum_gaolu + epoch_once\n",
    "gaolu_train_loss_list,gaolu_val_loss_list = model_gaolu.my_fit(X_gaolu_train, y_gaolu_train,\n",
    "                                    X_gaolu_val, y_gaolu_val, \n",
    "                                    gaolu_train_loss_list, gaolu_val_loss_list,\n",
    "                                    epochs=epoch_once, \n",
    "                                    batch_size=32,\n",
    "                                    lr = 0.002)\n",
    "\n",
    "print('\\nepoch_sum:',epoch_sum_gaolu)\n",
    "\n",
    "# 绘制训练和验证损失曲线\n",
    "plt.plot(gaolu_train_loss_list, label='Train Loss')\n",
    "plt.plot(gaolu_val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型建模效果\n",
    "y_train_pred_0,y_train_pred_1 = model_gaolu.my_predict(X_gaolu_train)\n",
    "y_test_pred_0,y_test_pred_1 = model_gaolu.my_predict(X_gaolu_test)\n",
    "\n",
    "base.double_control_train_test_result(scalers,  output_term,\n",
    "                                        y_gaolu_train,  y_train_pred_0, y_train_pred_1,\n",
    "                                        y_gaolu_test ,   y_test_pred_0,  y_test_pred_1)\n",
    "\n",
    "# base.double_control_train_test_result(scalers,  output_term,\n",
    "#                                         y_gaolu_train[:-1],  y_train_pred_0[1:], y_train_pred_1[1:],\n",
    "#                                         y_gaolu_test[:-1] ,   y_test_pred_0[1:],  y_test_pred_1[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建预测模型实例\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "model_predict = MyNeuralNetwork(input_size, hidden_size, output_size,ischuangxin)\n",
    "epoch_sum_predict = 0\n",
    "predict_train_loss_list = []\n",
    "predict_val_loss_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型训练\n",
    "epoch_once = epoch_once_time\n",
    "epoch_sum = epoch_sum_predict + epoch_once\n",
    "predict_train_loss_list, predict_val_loss_list = model_predict.my_fit(X_predict_train, y_predict_train,\n",
    "                                    X_predict_val, y_predict_val, \n",
    "                                    predict_train_loss_list, predict_val_loss_list,\n",
    "                                    epochs=epoch_once, \n",
    "                                    batch_size=64,\n",
    "                                    lr = 0.002)\n",
    "\n",
    "print('\\nepoch_sum:',epoch_sum_predict)\n",
    "\n",
    "\n",
    "# 绘制训练和验证损失曲线\n",
    "plt.plot(predict_train_loss_list, label='Train Loss')\n",
    "plt.plot(predict_val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型建模效果\n",
    "y_train_pred_0,y_train_pred_1 = model_predict.my_predict(X_predict_train)\n",
    "\n",
    "\n",
    "y_test_pred_0,y_test_pred_1 = model_predict.my_predict(X_predict_test)\n",
    "\n",
    "base.double_control_train_test_result(scalers,  output_term,\n",
    "                                        y_predict_train,  y_train_pred_0, y_train_pred_1,\n",
    "                                        y_predict_test,   y_test_pred_0,  y_test_pred_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.gaolu_predict_raw(scalers,output_term,model_predict,model_gaolu,X_predict_test,y_predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用NumPy重新构建神经网络架构\n",
    "class MyNeuralNetworkNumpy:\n",
    "    def __init__(self, model, input_size, hidden_size, output_size,ifchuangxin):\n",
    "        self.ifchuangxin = ifchuangxin\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        params = {name: param.detach().numpy() for name, param in model.state_dict().items()}\n",
    "        if cengshu == 3:    \n",
    "            self.weights_fc1 = params['fc1.weight']\n",
    "            self.bias_fc1 = params['fc1.bias']\n",
    "            self.weights_fc2 = params['fc2.weight']\n",
    "            self.bias_fc2 = params['fc2.bias']\n",
    "            self.weights_fc3 = params['fc3.weight']\n",
    "            self.bias_fc3 = params['fc3.bias']\n",
    "            self.weights_fc4 = params['fc4.weight']\n",
    "            self.bias_fc4 = params['fc4.bias']\n",
    "        elif cengshu == 2:  \n",
    "            self.weights_fc1 = params['fc1.weight']\n",
    "            self.bias_fc1 = params['fc1.bias']\n",
    "            self.weights_fc2 = params['fc2.weight']\n",
    "            self.bias_fc2 = params['fc2.bias']\n",
    "            self.weights_fc3 = params['fc3.weight']\n",
    "            self.bias_fc3 = params['fc3.bias']\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if cengshu == 3:    \n",
    "            if self.ifchuangxin:\n",
    "                hidden1 = np.dot(x, self.weights_fc1.T) + self.bias_fc1\n",
    "                hidden1 = self.relu(hidden1)\n",
    "\n",
    "                hidden2 = np.dot(hidden1, self.weights_fc2.T) + self.bias_fc2\n",
    "                hidden2 = self.relu(hidden2)\n",
    "\n",
    "                hidden3 = np.dot(hidden2, self.weights_fc3.T) + self.bias_fc3\n",
    "                hidden3 = self.relu(hidden3)\n",
    "\n",
    "                hidden4 = hidden1 + hidden2 + hidden3\n",
    "                output = np.dot(hidden4, self.weights_fc4.T) + self.bias_fc4\n",
    "\n",
    "            else:\n",
    "                hidden1 = np.dot(x, self.weights_fc1.T) + self.bias_fc1\n",
    "                hidden1 = self.relu(hidden1)\n",
    "\n",
    "                hidden2 = np.dot(hidden1, self.weights_fc2.T) + self.bias_fc2\n",
    "                hidden2 = self.relu(hidden2)\n",
    "\n",
    "                hidden3 = np.dot(hidden2, self.weights_fc3.T) + self.bias_fc3\n",
    "                hidden3 = self.relu(hidden3)\n",
    "\n",
    "                output = np.dot(hidden3, self.weights_fc4.T) + self.bias_fc4\n",
    "        elif cengshu == 2:  \n",
    "            if self.ifchuangxin:\n",
    "                hidden1 = np.dot(x, self.weights_fc1.T) + self.bias_fc1\n",
    "                hidden1 = self.relu(hidden1)\n",
    "\n",
    "                hidden2 = np.dot(hidden1, self.weights_fc2.T) + self.bias_fc2\n",
    "                hidden2 = self.relu(hidden2)\n",
    "\n",
    "                hidden3 = hidden1 + hidden2\n",
    "                output = np.dot(hidden3, self.weights_fc3.T) + self.bias_fc3\n",
    "                # hidden2 = self.relu(hidden2)\n",
    "\n",
    "                # hidden3 = np.concatenate([x, hidden1, hidden2], axis=1)  # 按列连接\n",
    "                # output = np.dot(hidden3, self.weights_fc3.T) + self.bias_fc3\n",
    "\n",
    "            else:\n",
    "                hidden1 = np.dot(x, self.weights_fc1.T) + self.bias_fc1\n",
    "                hidden1 = self.relu(hidden1)\n",
    "\n",
    "                hidden2 = np.dot(hidden1, self.weights_fc2.T) + self.bias_fc2\n",
    "                hidden2 = self.relu(hidden2)\n",
    "\n",
    "                output = np.dot(hidden2, self.weights_fc3.T) + self.bias_fc3\n",
    "\n",
    "\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def my_predict(self, data_input):\n",
    "        input = data_input  # 随机初始化一个输入序列\n",
    "        output_prediction = model_numpy.forward(input)\n",
    "        return output_prediction[:,0], output_prediction[:,1]\n",
    "\n",
    "# 使用NumPy模型进行预测\n",
    "model_numpy = MyNeuralNetworkNumpy(model_predict, input_size, hidden_size, output_size,ischuangxin)\n",
    "\n",
    "\n",
    "y_pred_0, y_pred_1 = model_numpy.my_predict(X_predict_test)\n",
    "\n",
    "# 计算 RMSE、MRE\n",
    "y_test = y_predict_test\n",
    "\n",
    "\n",
    "base.double_control_predict_result(scalers,output_term,y_test,y_pred_0,y_pred_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscontrol = True\n",
    "# iscontrol = False\n",
    "Times = 200\n",
    "# 过度系数  0.1 越小过度越快\n",
    "rou = 0.1\n",
    "if_add_noise = 1\n",
    "if_gaolu_is_predict = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成参考轨迹\n",
    "def get_yr(aim_value,current_value,alpha,P):\n",
    "    # 生成设定信号\n",
    "    setpoint_signal = np.full(10, aim_value)\n",
    "    # 初始化参数\n",
    "    alpha = alpha\n",
    "    y_r = np.zeros(P)\n",
    "    y_r[0] = current_value\n",
    "    # 模拟一阶模型\n",
    "    for k in range(1,P):\n",
    "        y_r[k] = alpha * y_r[k-1] + (1 - alpha) * aim_value\n",
    "\n",
    "    # # 绘制结果\n",
    "    # plt.plot(setpoint_signal, label='Setpoint Signal')\n",
    "    # plt.plot(y_r,'o-', label='Output Signal (Tracked)')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Time')\n",
    "    # plt.ylabel('Amplitude')\n",
    "    # plt.title('Tracking Setpoint Signal with One-Order Model')\n",
    "    # plt.show()\n",
    "    return y_r\n",
    "# 测试\n",
    "y_r = get_yr(1,-0.5,rou,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 生成期望数据\n",
    "\n",
    "def generate_y_aim_data(Times):\n",
    "    if Times == 400:\n",
    "        set_y1 = np.repeat(np.arange(1455, 1560, 5), 20)[10:410]\n",
    "        set_y2 = np.repeat(np.arange(0.34, 0.76, 0.02), 20)[0:400]\n",
    "        \n",
    "    elif Times == 200:\n",
    "        set_y1 = np.repeat(np.arange(1455, 1560, 5), 20)[10+75:410-125]\n",
    "        set_y2 = np.repeat(np.arange(0.34, 0.76, 0.02), 20)[0+75:400-125]\n",
    "\n",
    "    else:\n",
    "        set_y1 = np.full(Times,1500)\n",
    "        set_y2 = np.full(Times,0.45)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    set_y1_trans = scalers[output_term[0]].transform(set_y1.reshape(-1,1)).flatten()\n",
    "    set_y2_trans = scalers[output_term[1]].transform(set_y2.reshape(-1,1)).flatten()\n",
    "\n",
    "    return set_y1, set_y2, set_y1_trans, set_y2_trans\n",
    "set_y1, set_y2, set_y1_trans, set_y2_trans = generate_y_aim_data(Times)\n",
    "print(set_y1.shape)\n",
    "print(set_y1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成控制时域的数据格式\n",
    "def generate_k_data(u1_data, u2_data, u3_data, u4_data, y1_data,y2_data, num_samples, P):\n",
    "    nearest_index = np.abs(y1_data - (-0.5)).argmin()\n",
    "    # 生成随机索引值\n",
    "    #从原有数据的randint时刻开始往下进行控制\n",
    "    randint = np.random.randint(1, num_samples - 2 - P - 1)\n",
    "    randint = nearest_index  # 如果你希望使用固定的值而不是随机生成\n",
    "    # randint = 250  # 如果你希望使用固定的值而不是随机生成\n",
    "    print(randint)\n",
    "    # 提取数据并构成 k_data\n",
    "    # 第一次得到下面五个变量，固定好格式构成k_data\n",
    "    u1   = u1_data[randint  :randint+3  ]\n",
    "    u2   = u2_data[randint  :randint+3  ]\n",
    "    u3   = u3_data[randint  :randint+3  ]\n",
    "    u4   = u4_data[randint  :randint+3  ]\n",
    "\n",
    "    y1   = y1_data[randint  :randint+3  ]\n",
    "    y2   = y2_data[randint  :randint+3  ]\n",
    "    k_data = np.concatenate((u1, u2, u3, u4, y1, y2), axis=0)\n",
    "    print(k_data.shape)\n",
    "\n",
    "    k_data = np.zeros_like(k_data)\n",
    "    return k_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义单时刻的MPC问题优化\n",
    "def my_MPC(k_data,params,M,P,y1_aim,y2_aim,isprint):\n",
    "\n",
    "    h1 = 1.0\n",
    "    h2 = 1.0\n",
    "    lamda1 = 0.001\n",
    "    lamda2 = 0.001\n",
    "    lamda3 = 0.001\n",
    "    lamda4 = 0.001\n",
    "    y1_percent = 1.0\n",
    "    y2_percent = 1.0\n",
    "\n",
    "    # 从固定格式k_data里面读取信息\n",
    "    u1   = k_data[0:3]\n",
    "    u2   = k_data[3:6]\n",
    "    u3   = k_data[6:9]\n",
    "    u4   = k_data[9:12]\n",
    "\n",
    "    y1   = k_data[12:15]\n",
    "    y2   = k_data[15:18]\n",
    "\n",
    "    \n",
    "    # 获取猜测值[h U1 U2]\n",
    "    # h, U1, U2  =params[0], params[1:M+1],params[M+1:]\n",
    "    U1, U2, U3, U4  =params[0:M], params[M:2*M],params[2*M:3*M], params[3*M:4*M]\n",
    "    \n",
    "    # 整理数据见   MPC推到.escel\n",
    "    u1   = np.concatenate((u1,U1,U1[-1]*np.ones(P-M)))\n",
    "    u2   = np.concatenate((u2,U2,U2[-1]*np.ones(P-M)))\n",
    "    u3   = np.concatenate((u3,U3,U3[-1]*np.ones(P-M)))\n",
    "    u4   = np.concatenate((u4,U4,U4[-1]*np.ones(P-M)))\n",
    "    y1   = np.concatenate((y1,np.zeros(P)))\n",
    "    y2   = np.concatenate((y2,np.zeros(P)))\n",
    "    if isprint:\n",
    "        print(u1.round(4))\n",
    "        print(u2.round(4))\n",
    "        print(u3.round(4))\n",
    "        print(u4.round(4))\n",
    "        print(y1.round(4))    \n",
    "        print(y2.round(4))\n",
    "        print('开始预测')\n",
    "\n",
    "    y1_k = y1[2]\n",
    "    y2_k = y2[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 总共预测 P+1 次\n",
    "    # 对k时刻进行预测-----1次\n",
    "    for j in range(1):   # j = 0\n",
    "        x = np.column_stack((   u1[j+2],u2[j+2],u3[j+2],u4[j+2],\n",
    "                                u1[j+1],u2[j+1],u3[j+1],u4[j+1],\n",
    "                                y1[j+1],y2[j+1]))\n",
    "        # x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y1_m_k, y2_m_k = model_numpy.my_predict(x)\n",
    "        E1_k = y1_k - y1_m_k\n",
    "        E2_k = y2_k - y2_m_k\n",
    "        if isprint:\n",
    "            print(j,'mode = 0')\n",
    "            print(x.round(4))\n",
    "            print(y1_k.round(4),y2_k.round(4))\n",
    "            print(y1_m_k.round(4),y2_m_k.round(4))\n",
    "\n",
    "    # 对控制时刻进行预测-----M次\n",
    "    for j in range(1,M+1):  # j = 1,2\n",
    "        x = np.column_stack((   u1[j+2],u2[j+2],u3[j+2],u4[j+2],\n",
    "                                u1[j+1],u2[j+1],u3[j+1],u4[j+1],\n",
    "                                y1[j+1],y2[j+1]))\n",
    "        # x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y1_k_j, y2_k_j = model_numpy.my_predict(x)\n",
    "        y1[j+2] = y1_k_j.item()\n",
    "        y2[j+2] = y2_k_j.item()\n",
    "        if isprint:\n",
    "            print(j,'mode = 1')\n",
    "            print(x.round(4))\n",
    "            print(y1_k_j.round(4),y2_k_j.round(4))\n",
    "            print('更新后:')\n",
    "            print(u1.round(4))\n",
    "            print(u2.round(4))\n",
    "            print(u3.round(4))\n",
    "            print(u4.round(4))\n",
    "            print(u5.round(4))\n",
    "            print(u6.round(4))\n",
    "            print(u7.round(4))\n",
    "            print(y1.round(4))    \n",
    "            print(y2.round(4))\n",
    "\n",
    "    # 对控制时域外的部分进行预测-----P-M次\n",
    "    # 注意：这部分的信号是保持控制不变下进行\n",
    "    for j in range(M+1,P+1):  #j = 3,4\n",
    "        x = np.column_stack((   u1[j+2],u2[j+2],u3[j+2],u4[j+2],\n",
    "                                u1[j+1],u2[j+1],u3[j+1],u4[j+1],\n",
    "                                y1[j+1],y2[j+1]))\n",
    "        # x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y1_k_j, y2_k_j = model_numpy.my_predict(x)\n",
    "        y1[j+2] = y1_k_j.item()#将预测值作为下一步的输出值\n",
    "        y2[j+2] = y2_k_j.item()\n",
    "        if isprint:\n",
    "            print(j,'mode = 2')\n",
    "            print(x.round(4))\n",
    "            print(y1_k_j.round(4),y2_k_j.round(4))\n",
    "            print('更新后:')\n",
    "            print(u1.round(4))\n",
    "            print(u2.round(4))\n",
    "            print(u3.round(4))\n",
    "            print(u4.round(4))\n",
    "            print(y1.round(4))    \n",
    "            print(y2.round(4))\n",
    "\n",
    "\n",
    "\n",
    "    k_data2 = np.concatenate((u1[1:4],u2[1:4],u3[1:4],u4[1:4],y1[1:4],y2[1:4]),axis=0)\n",
    "    if isprint:\n",
    "        print('更新k_data')\n",
    "        print(k_data2.round(4))\n",
    "\n",
    "\n",
    "    #获取参考轨迹\n",
    "    # 一定要对照好做差的序列\n",
    "    y1_r_aim  = get_yr(y1_aim,y1_k,rou,P+1)\n",
    "    y1_r = y1_r_aim[1:] \n",
    "\n",
    "\n",
    "    y2_r_aim  = get_yr(y2_aim,y2_k,rou,P+1)\n",
    "    y2_r = y2_r_aim[1:] \n",
    "\n",
    "    y1_M_k = y1[3:]\n",
    "    y2_M_k = y2[3:]\n",
    "    if isprint==1:\n",
    "        print('反馈补偿:')\n",
    "        print('y1_k',y1_k.round(4))  \n",
    "        print('y1_m_k',y1_m_k.round(4))    \n",
    "        print('h*E1_k',(h1*E1_k).round(4)) \n",
    "        print('y2_k',y2_k.round(4))  \n",
    "        print('y2_m_k',y2_m_k.round(4))   \n",
    "        print('h*E2_k',(h2*E2_k).round(4))\n",
    "\n",
    "        print('temp:')\n",
    "        print('y1_aim',y1_aim.round(4))\n",
    "        print('y1_r_aim',y1_r_aim.round(4))\n",
    "        print('y1_r',y1_r.round(4))\n",
    "        print('y1_M_k',y1_M_k.round(4))\n",
    "        print('y1_M_k+h1*E1_k',(y1_M_k+h1*E1_k).round(4))\n",
    "\n",
    "        print('Si_percent:')\n",
    "        print('y2_aim',y2_aim.round(4))\n",
    "        print('y2_r_aim',y2_r_aim.round(4))\n",
    "        print('y2_r',y2_r.round(4))\n",
    "        print('y2_M_k',y2_M_k.round(4))\n",
    "        print('y2_M_k+h2*E2_k',(y2_M_k+h2*E2_k).round(4))\n",
    "\n",
    "        print('u:')\n",
    "        print(u1[2:].round(4))\n",
    "        print(u2[2:].round(4))\n",
    "        print(u3[2:].round(4))\n",
    "        print(u4[2:].round(4))\n",
    "        \n",
    "    # 计算mse\n",
    "    # lamda1太大的话会导致y1_r和y1_M_k的误差加大*****************导致超调的原因\\与目标值之间存在间隙\n",
    "\n",
    "\n",
    "    y1_err = y1_percent*np.sum((y1_r-(y1_M_k+h1*E1_k))**2) \n",
    "    y2_err = y2_percent*np.sum((y2_r-(y2_M_k+h2*E2_k))**2) \n",
    "    u1_power = lamda1*np.sum((np.diff(u1[2:]))**2)\n",
    "    u2_power = lamda2*np.sum((np.diff(u2[2:]))**2)\n",
    "    u3_power = lamda3*np.sum((np.diff(u3[2:]))**2)\n",
    "    u4_power = lamda4*np.sum((np.diff(u4[2:]))**2)\n",
    "\n",
    "    # y1_err = y1_percent*np.sum(np.fabs(y1_r-(y1_M_k+h1*E1_k))) \n",
    "    # y2_err = y2_percent*np.sum(np.fabs(y2_r-(y2_M_k+h2*E2_k))) \n",
    "    # u1_power = lamda1*np.sum((np.fabs(np.diff(u1))))\n",
    "    # u2_power = lamda2*np.sum((np.fabs(np.diff(u2))))\n",
    "    # u3_power = lamda3*np.sum((np.fabs(np.diff(u3))))\n",
    "    # u4_power = lamda4*np.sum((np.fabs(np.diff(u4))))\n",
    "    # u5_power = lamda2*np.sum((np.fabs(np.diff(u5))))\n",
    "    # u6_power = lamda3*np.sum((np.fabs(np.diff(u6))))\n",
    "    # u7_power = lamda4*np.sum((np.fabs(np.diff(u7))))\n",
    "\n",
    "    mse = (0\n",
    "            +y1_err\n",
    "            +y2_err\n",
    "            +u1_power\n",
    "            +u2_power\n",
    "            +u3_power\n",
    "            +u4_power\n",
    "            )\n",
    "    \n",
    "    # print('mse {:.7f}'.format(mse))\n",
    "    if isprint==1:\n",
    "        print('mse {:.7f}'.format(mse))\n",
    "        print('1111 {:.7f}'.format(y1_err))\n",
    "        print('2222 {:.7f}'.format(y2_err))\n",
    "        print('1111 {:.7f}'.format(u1_power))\n",
    "        print('2222 {:.7f}'.format(u2_power))\n",
    "        print('3333 {:.7f}'.format(u3_power))\n",
    "        print('4444 {:.7f}'.format(u4_power))\n",
    "\n",
    "\n",
    "\n",
    "    return mse , k_data2, E1_k*h1,  E2_k*h2\n",
    "    # return mse , k_data2, E1_k*h1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成高斯噪声,设置随机种子，以便结果可重现\n",
    "np.random.seed(42)\n",
    "gaussian_noise_SI = np.random.normal(0,d_yuansu*0.001,Times)\n",
    "gaussian_noise_TEMP = np.random.normal(0,d_temp*0.1,Times)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(gaussian_noise_SI)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(gaussian_noise_TEMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_update_model = True\n",
    "if_update_model = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(model_predict,model_gaolu,x,gaolu_data_past_x,gaolu_data_past_y):\n",
    "    y1_pred, y2_pred = model_gaolu.my_predict(x)\n",
    "    y_label = np.column_stack((y1_pred, y2_pred))\n",
    "    gaolu_data_past_x.append(x)\n",
    "    gaolu_data_past_y.append(y_label)\n",
    "\n",
    "    \n",
    "    X_modified = np.array(gaolu_data_past_x)\n",
    "    y_modified = np.array(gaolu_data_past_y)\n",
    "    # print(X_modified)\n",
    "    # print(y_modified)\n",
    "    X = X_modified.reshape(X_modified.shape[0],X_modified.shape[2])\n",
    "    Y = y_modified.reshape(y_modified.shape[0],y_modified.shape[2])\n",
    "    print(X_modified.shape)\n",
    "    print(y_modified.shape)\n",
    "    if y_modified.shape[0]% 1 == 0:\n",
    "        model_predict.model_update(X, Y,\n",
    "                                epochs=10, \n",
    "                                batch_size=64,\n",
    "                                lr = 0.002)\n",
    "        # gaolu_data_past_x = []\n",
    "        # gaolu_data_past_y = []\n",
    "\n",
    "    return model_predict,model_gaolu,gaolu_data_past_x,gaolu_data_past_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对未来Times周期预测控制\n",
    "max_control = 1.0\n",
    "# 期望设定值\n",
    "set_y1, set_y2, set_y1_trans, set_y2_trans = generate_y_aim_data(Times)\n",
    "\n",
    "# MPC参数\n",
    "P = 3  # 预测时域长度  3\n",
    "M = 3  # 4\n",
    "#生成控制时域的数据格式\n",
    "k_data = generate_k_data(u1_data, u2_data, u3_data, u4_data,\n",
    "                        y1_data, y2_data, num_samples, P)\n",
    "\n",
    "\n",
    "# MPC控制循环   迭代的只有：k_data\n",
    "all_pred_y1 = []\n",
    "all_pred_y2 = []\n",
    "all_pred_u1 = []\n",
    "all_pred_u2 = []\n",
    "all_pred_u3 = []\n",
    "all_pred_u4 = []\n",
    "gaolu_data_past_x = []\n",
    "gaolu_data_past_y = []\n",
    "\n",
    "\n",
    "# MPC控制循环40\n",
    "for k in range(Times):\n",
    "    if iscontrol == False:\n",
    "        break\n",
    "\n",
    "    print(f\"这是对第{k}时刻的最优U1、U2输入求解\")\n",
    "\n",
    "    # 定义优化目标函数\n",
    "    def objective_function(params, *k_data):\n",
    "        mse, k_data2, E1_k_0, E2_k_0 = my_MPC(k_data=k_data[0], params=params, \n",
    "                                M=M, P=P, \n",
    "                                y1_aim = set_y1_trans[k], y2_aim = set_y2_trans[k],\n",
    "                                isprint = 0) \n",
    "        return mse\n",
    "    \n",
    "    # 初始猜测值[h U1 U2]   定义参数的上下限    设置退出条件\n",
    "    params = np.concatenate([np.ones(M), np.ones(M),np.ones(M), np.ones(M)])\n",
    "    bounds = [(-max_control, max_control) for _ in range(4 * M)]\n",
    "    exit_conditions = {'maxiter': 1000} \n",
    "    # 进行优化\n",
    "    result = minimize(objective_function, params, method='L-BFGS-B', \n",
    "                    bounds=bounds, args=k_data)#args传进来的是一个元组\n",
    "\n",
    "\n",
    "    U1, U2, U3, U4 =    result.x[0:M], result.x[M:2*M], \\\n",
    "                        result.x[2*M:3*M], result.x[3*M:4*M]\n",
    "    \n",
    "\n",
    "    u1   = k_data[0:3]\n",
    "    u2   = k_data[3:6]\n",
    "    u3   = k_data[6:9]\n",
    "    u4   = k_data[9:12]\n",
    "\n",
    "    y1   = k_data[12:15]\n",
    "    y2   = k_data[15:18]\n",
    "    u1   = np.concatenate((u1,U1,U1[-1]*np.ones(P-M)))\n",
    "    u2   = np.concatenate((u2,U2,U2[-1]*np.ones(P-M)))\n",
    "    u3   = np.concatenate((u3,U3,U3[-1]*np.ones(P-M)))\n",
    "    u4   = np.concatenate((u4,U4,U4[-1]*np.ones(P-M)))\n",
    "    y1   = np.concatenate((y1,np.zeros(P)))\n",
    "    y2   = np.concatenate((y2,np.zeros(P)))\n",
    "\n",
    "\n",
    "\n",
    "    # 将控制序列第一个数作用于高炉\n",
    "    j = 1\n",
    "    x = np.column_stack((   u1[j+2],u2[j+2],u3[j+2],u4[j+2],\n",
    "                            u1[j+1],u2[j+1],u3[j+1],u4[j+1],\n",
    "                            y1[j+1],y2[j+1]))\n",
    "    # x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "    y1_pred0, y2_pred0 = model_predict.my_predict(x)\n",
    "    if if_gaolu_is_predict:\n",
    "        y1_pred, y2_pred = model_predict.my_predict(x)\n",
    "        if if_add_noise:\n",
    "            y1_pred = y1_pred+gaussian_noise_TEMP[k].item()\n",
    "            y2_pred = y2_pred+gaussian_noise_SI[k].item()\n",
    "    else:\n",
    "        y1_pred, y2_pred = model_gaolu.my_predict(x)\n",
    "        if if_update_model:\n",
    "            model_predict,model_gaolu,gaolu_data_past_x,gaolu_data_past_y = update_model(model_predict,model_gaolu,x,gaolu_data_past_x,gaolu_data_past_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 更新k_data\n",
    "    params = np.concatenate((U1, U2, U3, U4),axis=0)\n",
    "    mse, k_data2, E1_k_0, E2_k_0 =my_MPC(k_data=k_data,params=params,\n",
    "                            M=M,P=P, \n",
    "                            y1_aim = set_y1_trans[k], y2_aim = set_y2_trans[k],\n",
    "                            isprint = 0) \n",
    "\n",
    "\n",
    "    print(  '1设定',set_y1_trans[k].round(4),\\\n",
    "            '预测',y1_pred0.round(4),\\\n",
    "            '高炉', y1_pred.round(4),\\\n",
    "            '高炉与设定误差',(set_y1_trans[k]-y1_pred).round(4),(set_y1_trans[k]-y1_pred).round(4)/d_temp,\\\n",
    "            '模型误差',(y1_pred0 - y1_pred).round(4),\\\n",
    "            '校正值',E1_k_0.round(4))\n",
    "    print(  '2设定',set_y2_trans[k].round(4),\\\n",
    "            '预测',y2_pred0.round(4),\\\n",
    "            '高炉', y2_pred.round(4),\\\n",
    "            '高炉与设定误差',(set_y2_trans[k]-y2_pred).round(4),(set_y2_trans[k]-y2_pred).round(4)/d_yuansu,\\\n",
    "            '模型误差',(y2_pred0 - y2_pred).round(4),\\\n",
    "            '校正值',E2_k_0.round(4))\n",
    "\n",
    "\n",
    "\n",
    "    all_pred_y1.append(y1_pred)\n",
    "    all_pred_y2.append(y2_pred)\n",
    "    all_pred_u1.append(U1[0])\n",
    "    all_pred_u2.append(U2[0])\n",
    "    all_pred_u3.append(U3[0])\n",
    "    all_pred_u4.append(U4[0])\n",
    "    k_data2[14] = y1_pred.item()\n",
    "    k_data2[17] = y2_pred.item()\n",
    "    k_data = k_data2\n",
    "    # 进入下一时刻，更新预测时域、控制时域，即k_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startt = 50\n",
    "endd = 150\n",
    "\n",
    "\n",
    "font222 = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=10)  # 替换为你的中文字体文件路径\n",
    "\n",
    "y1_pred_inverse_transform = scalers[output_term[0]].inverse_transform(np.array(all_pred_y1[startt:endd]).reshape(-1, 1)).flatten()\n",
    "y2_pred_inverse_transform = scalers[output_term[1]].inverse_transform(np.array(all_pred_y2[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u1_inverse_transform = scalers[input_term[0]].inverse_transform(np.array(all_pred_u1[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u2_inverse_transform = scalers[input_term[1]].inverse_transform(np.array(all_pred_u2[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u3_inverse_transform = scalers[input_term[2]].inverse_transform(np.array(all_pred_u3[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u4_inverse_transform = scalers[input_term[3]].inverse_transform(np.array(all_pred_u4[startt:endd]).reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "a1 = scalers[input_term[0]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a2 = scalers[input_term[1]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a3 = scalers[input_term[2]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a4 = scalers[input_term[3]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "print(f'上线分别是：{a1}、{a2}、{a3}、{a4}')\n",
    "\n",
    "\n",
    "rmse_1 = np.mean(np.fabs(set_y1[startt:endd]-y1_pred_inverse_transform))\n",
    "rmse_2 = np.mean(np.fabs(set_y2[startt:endd]-y2_pred_inverse_transform))\n",
    "print('平均误差',rmse_1.round(4))\n",
    "print('平均误差',rmse_2.round(4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 模型预测控制结果可视化\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(8, 13))\n",
    "\n",
    "# 第一个维度的曲线\n",
    "ax = plt.subplot(6, 1, 1)\n",
    "plt.plot(set_y1[startt:endd], 'k.-', label='设定值')\n",
    "plt.plot(y1_pred_inverse_transform, 'r', label='MLP')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel('铁水温度MIT/℃', fontproperties=font)  # 使用中文标签\n",
    "plt.legend(prop=font222)\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)  # 固定纵坐标标签在最左边\n",
    "\n",
    "input_term222 =        ['富氧流量/(m\\u00b3/h)', '设定喷煤量/(t/h)', '热风压力/kPa', '热风温度/℃']\n",
    "output_term222 = ['铁水温度MIT/℃', '铁水硅含量[Si]/%']\n",
    "time_term= '时间戳h'\n",
    "input_term333 =        ['富氧流量', '设定喷煤量', '热风压力', '热风温度']\n",
    "output_term333 = ['铁水温度MIT', '铁水硅含量[Si]']\n",
    "time_term= '时间戳h'\n",
    "# 用于子图编号的字母序列\n",
    "subplot_labels = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)']\n",
    "dtiem = -0.5\n",
    "\n",
    "\n",
    "ax.text(0.5, dtiem, f'{subplot_labels[0]} {output_term333[0]}数据', \n",
    "            transform=ax.transAxes, ha='center', fontproperties=font)  # 添加每个子图的标题在下方\n",
    "    # 添加横坐标标题\n",
    "ax.set_xlabel('控制周期', fontproperties=font)  # 只给最下面的子图添加横坐标标签\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 第二个维度的曲线\n",
    "ax = plt.subplot(6, 1, 2)\n",
    "plt.plot(set_y2[startt:endd], 'k.-')\n",
    "plt.plot(y2_pred_inverse_transform, 'r')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel('铁水硅含量[Si]/%', fontproperties=font)  # 使用中文标签\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "ax.text(0.5, dtiem, f'{subplot_labels[1]} {output_term333[1]}数据', \n",
    "            transform=ax.transAxes, ha='center', fontproperties=font)  # 添加每个子图的标题在下方\n",
    "    # 添加横坐标标题\n",
    "ax.set_xlabel('控制周期', fontproperties=font)  # 只给最下面的子图添加横坐标标签\n",
    "# 第一个维度的u1曲线\n",
    "ax = plt.subplot(6, 1, 3)\n",
    "plt.plot(all_pred_u1_inverse_transform, 'r')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term222[0], fontproperties=font)  # 使用中文标签\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)  # 固定纵坐标标签在最左边\n",
    "ax.text(0.5, dtiem, f'{subplot_labels[2]} {input_term333[0]}数据', \n",
    "            transform=ax.transAxes, ha='center', fontproperties=font)  # 添加每个子图的标题在下方\n",
    "    # 添加横坐标标题\n",
    "ax.set_xlabel('控制周期', fontproperties=font)  # 只给最下面的子图添加横坐标标签\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "ax = plt.subplot(6, 1, 4)\n",
    "plt.plot(all_pred_u2_inverse_transform, 'r')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term222[1], fontproperties=font)  # 使用中文标签\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)  # 固定纵坐标标签在最左边\n",
    "ax.text(0.5, dtiem, f'{subplot_labels[3]} {input_term333[1]}数据', \n",
    "            transform=ax.transAxes, ha='center', fontproperties=font)  # 添加每个子图的标题在下方\n",
    "    # 添加横坐标标题\n",
    "ax.set_xlabel('控制周期', fontproperties=font)  # 只给最下面的子图添加横坐标标签\n",
    "\n",
    "# 第三个维度的u3曲线\n",
    "ax = plt.subplot(6, 1, 5)\n",
    "plt.plot(all_pred_u3_inverse_transform, 'r')  # 修改标签为 'u3'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term222[2], fontproperties=font)  # 使用中文标签\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)  # 固定纵坐标标签在最左边\n",
    "ax.text(0.5, dtiem, f'{subplot_labels[4]} {input_term333[2]}数据', \n",
    "            transform=ax.transAxes, ha='center', fontproperties=font)  # 添加每个子图的标题在下方\n",
    "    # 添加横坐标标题\n",
    "ax.set_xlabel('控制周期', fontproperties=font)  # 只给最下面的子图添加横坐标标签\n",
    "\n",
    "# 第四个维度的u4曲线\n",
    "ax = plt.subplot(6, 1, 6)\n",
    "plt.plot(all_pred_u4_inverse_transform, 'r')  # 修改标签为 'u4'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term222[3], fontproperties=font)  # 使用中文标签\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)  # 固定纵坐标标签在最左边\n",
    "ax.text(0.5, dtiem, f'{subplot_labels[5]} {input_term333[3]}数据', \n",
    "            transform=ax.transAxes, ha='center', fontproperties=font)  # 添加每个子图的标题在下方\n",
    "    # 添加横坐标标题\n",
    "ax.set_xlabel('控制周期', fontproperties=font)  # 只给最下面的子图添加横坐标标签\n",
    "\n",
    "\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startt = 50\n",
    "endd = 150\n",
    "\n",
    "y1_pred_inverse_transform = scalers[output_term[0]].inverse_transform(np.array(all_pred_y1[startt:endd]).reshape(-1, 1)).flatten()\n",
    "y2_pred_inverse_transform = scalers[output_term[1]].inverse_transform(np.array(all_pred_y2[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u1_inverse_transform = scalers[input_term[0]].inverse_transform(np.array(all_pred_u1[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u2_inverse_transform = scalers[input_term[1]].inverse_transform(np.array(all_pred_u2[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u3_inverse_transform = scalers[input_term[2]].inverse_transform(np.array(all_pred_u3[startt:endd]).reshape(-1, 1)).flatten()\n",
    "all_pred_u4_inverse_transform = scalers[input_term[3]].inverse_transform(np.array(all_pred_u4[startt:endd]).reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# # 将数据转换为DataFrame\n",
    "# data = {\n",
    "#     'set_y1': set_y1,\n",
    "#     'set_y2': set_y2,\n",
    "#     'MLP_y1': y1_pred_inverse_transform,\n",
    "#     'MLP_y2': y2_pred_inverse_transform,\n",
    "#     'MLP_u1': all_pred_u1_inverse_transform,\n",
    "#     'MLP_u2': all_pred_u2_inverse_transform,\n",
    "#     'MLP_u3': all_pred_u3_inverse_transform,\n",
    "#     'MLP_u4': all_pred_u4_inverse_transform\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # 保存DataFrame到Excel文件\n",
    "# df.to_excel('pred_data_MLP_'+str(cengshu)+'.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "a1 = scalers[input_term[0]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a2 = scalers[input_term[1]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a3 = scalers[input_term[2]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a4 = scalers[input_term[3]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "print(f'上线分别是：{a1}、{a2}、{a3}、{a4}')\n",
    "\n",
    "\n",
    "rmse_1 = np.mean(np.fabs(set_y1[startt:endd]-y1_pred_inverse_transform))\n",
    "rmse_2 = np.mean(np.fabs(set_y2[startt:endd]-y2_pred_inverse_transform))\n",
    "print('平均误差',rmse_1.round(4))\n",
    "print('平均误差',rmse_2.round(4))\n",
    "\n",
    "# 模型预测控制结果可视化\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(set_y1[startt:endd], 'ro-', label='设定值')\n",
    "plt.plot(y1_pred_inverse_transform, 'bo-', label='MLP 实际值')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend(prop=font)\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(set_y2[startt:endd], 'ro-')\n",
    "plt.plot(y2_pred_inverse_transform, 'bo-')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# 第一个维度的u1曲线\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(all_pred_u1_inverse_transform, 'bo-')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(all_pred_u2_inverse_transform, 'bo-')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第三个维度的u3曲线\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(all_pred_u3_inverse_transform, 'bo-')  # 修改标签为 'u3'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[2], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第四个维度的u4曲线\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(all_pred_u4_inverse_transform, 'bo-')  # 修改标签为 'u4'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[3], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iscontrol:\n",
    "    y1_pred_inverse_transform = scalers[output_term[0]].inverse_transform(np.array(all_pred_y1).reshape(-1, 1)).flatten()\n",
    "    y2_pred_inverse_transform = scalers[output_term[1]].inverse_transform(np.array(all_pred_y2).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    startt = 0\n",
    "    endd = 400\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(set_y1[startt:endd],'r', label='设定值')\n",
    "    plt.plot(y1_pred_inverse_transform[startt:endd],'b', label='实际值')\n",
    "    plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "    plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "    plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "    plt.legend(prop=font)\n",
    "    plt.title(f\"模型:MLP 训练次数:{epoch_sum_gaolu} 隐含层数:{3} 改进:{ischuangxin} 动态更新:{if_update_model} P:{P} M:{M} \", fontproperties=font)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(set_y2[startt:endd],'r')\n",
    "    plt.plot(y2_pred_inverse_transform[startt:endd],'b')\n",
    "    plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "    plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "    plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iscontrol:\n",
    "    y1_pred_inverse_transform = scalers[output_term[0]].inverse_transform(np.array(all_pred_y1).reshape(-1, 1)).flatten()\n",
    "    y2_pred_inverse_transform = scalers[output_term[1]].inverse_transform(np.array(all_pred_y2).reshape(-1, 1)).flatten()\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(set_y1[startt:endd],'r', label='设定值')\n",
    "    plt.plot(y1_pred_inverse_transform[startt:endd],'b', label='实际值')\n",
    "    plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "    plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "    plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "    plt.legend(prop=font)\n",
    "    plt.title(f\"模型:MLP 训练次数:{epoch_sum_gaolu} 隐含层数:{3} 改进:{ischuangxin} P:{P} M:{M} \", fontproperties=font)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(set_y2[startt:endd],'r')\n",
    "    plt.plot(y2_pred_inverse_transform[startt:endd],'b')\n",
    "    plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "    plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "    plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "# 第一个维度的u1曲线\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(all_pred_u1_inverse_transform, 'bo-')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(all_pred_u2_inverse_transform, 'bo-')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第三个维度的u3曲线\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(all_pred_u3_inverse_transform, 'bo-')  # 修改标签为 'u3'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[2], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第四个维度的u4曲线\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(all_pred_u4_inverse_transform, 'bo-')  # 修改标签为 'u4'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,endd-startt))\n",
    "plt.ylabel(input_term[3], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据转换、\n",
    "if iscontrol:\n",
    "    base.data_tranform_plot_4_2(scalers,Times ,max_control,\n",
    "                        output_term,input_term,\n",
    "                        set_y1,set_y2,set_y1_trans,set_y2_trans,\n",
    "                        all_pred_y1, all_pred_y2,\n",
    "                        all_pred_u1,\n",
    "                        all_pred_u2,\n",
    "                        all_pred_u3,\n",
    "                        all_pred_u4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
