{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 库文件\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import gp_minimize\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "# 设置中文字体\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=12)  # 替换为你的中文字体文件路径\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "excel_path = f'C:\\\\Users\\\\haokw\\\\Documents\\\\GitHub\\\\gaolu\\\\MPC\\\\高炉\\\\0数据\\\\数据-时间戳.xlsx'\n",
    "df_sheet = pd.read_excel(excel_path, sheet_name='Sheet4') \n",
    "# print(df_sheet.info())\n",
    "print(df_sheet.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入输出参数\n",
    "input_term = ['富氧流量', '冷风流量', '热风温度', '设定喷煤量']\n",
    "output_term = ['铁口1温度插补', 'SI插补']\n",
    "time_term= '主参数时间戳'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常数据处理-处理前后对比\n",
    "# 创建数据框副本以避免修改原始数据\n",
    "df_sheet_process = df_sheet.copy()\n",
    "\n",
    "# 定义一个函数，用中位数替换异常值\n",
    "def replace_outliers_with_median(series):\n",
    "    # 计算列的中位数\n",
    "    median_value = series.median()\n",
    "    # 检测异常值\n",
    "    outliers = (series - median_value).abs() > 3.0 * series.std()  # 使用标准差作为阈值\n",
    "    # 使用中位数替换异常值\n",
    "    series[outliers] = median_value\n",
    "# 画出数据\n",
    "def plot_subplot(data_x,data_y_yuan,data_y,column):\n",
    "    plt.plot(data_x,data_y_yuan,'r-')\n",
    "    plt.plot(data_x,data_y,'m-')\n",
    "    # plt.xlabel(time_term, fontproperties=font)  # 使用中文标签\n",
    "    plt.ylabel(column, fontproperties=font)  # 使用中文标签\n",
    "    # 使用中文标签\n",
    "\n",
    "\n",
    "# 对指定列应用替代异常值的函数\n",
    "# replace_outliers_with_median(df_sheet_process[input_term[0]])\n",
    "# replace_outliers_with_median(df_sheet_process[input_term[1]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[0]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[1]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[2]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[3]])\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# for idx, column in enumerate(input_term+output_term):\n",
    "    \n",
    "#     plt.subplot(len(input_term+output_term), 1, idx+1)\n",
    "#     plot_subplot(df_sheet_process[time_term].values,df_sheet[column].values,df_sheet_process[column].values,column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出选取的数据\n",
    "def plot_subplot(data_x,data_y,column,index_predict,index_gaolu):\n",
    "    plt.plot(data_x,data_y,'-')\n",
    "    plt.plot(data_x[index_gaolu],data_y[index_gaolu],'m-')\n",
    "    plt.plot(data_x[index_predict],data_y[index_predict],'r-')\n",
    "    \n",
    "    # plt.xlabel(time_term, fontproperties=font)  # 使用中文标签\n",
    "    plt.ylabel(column, fontproperties=font)  # 使用中文标签\n",
    "\n",
    "# index = range(1300, 2500, 1)\n",
    "# index = range(4500, 6550, 1)\n",
    "\n",
    "# index = range(5000, 5610, 1)\n",
    "    \n",
    "# length = 3000\n",
    "# start1 = 200\n",
    "# start2 = 4000   829\n",
    "\n",
    "length1 = 500\n",
    "start1 = 0\n",
    "length2 = 827\n",
    "start2 = 0\n",
    "\n",
    "\n",
    "# length = 280\n",
    "# start1 = 3550\n",
    "# start2 = 4000\n",
    "index_predict   = range(start1, start1+length1+1, 1)\n",
    "index_gaolu     = range(start2, start2+length2+1, 1)\n",
    "# index = range(1, 7572, 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, column in enumerate(input_term+output_term):\n",
    "    plt.subplot(len(input_term+output_term), 1, idx+1)\n",
    "    plot_subplot(df_sheet_process[time_term].values,df_sheet_process[column].values,column,index_predict,index_gaolu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化、逆归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 将数据存储为字典，每个键对应一列数据\n",
    "original_data_dict = {\n",
    "    input_term[0]:   df_sheet[input_term[0]].values,\n",
    "    input_term[1]:   df_sheet[input_term[1]].values,\n",
    "    input_term[2]:   df_sheet[input_term[2]].values,\n",
    "    input_term[3]:   df_sheet[input_term[3]].values,\n",
    "    output_term[0]:  df_sheet[output_term[0]].values,\n",
    "    output_term[1]:  df_sheet[output_term[1]].values\n",
    "}\n",
    "\n",
    "# 初始化缩放器\n",
    "scalers = {}\n",
    "\n",
    "# 进行拟合\n",
    "for column, data in original_data_dict.items():\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler.fit(data.reshape(-1, 1))  # 保证数据是列向量\n",
    "    scalers[column] = scaler\n",
    "\n",
    "# 进行归一化\n",
    "normalized_data_dict = {}\n",
    "for column, scaler in scalers.items():\n",
    "    normalized_data_dict[column] = scaler.transform(original_data_dict[column].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 进行反归一化\n",
    "original_data_dict = {}\n",
    "for column, scaler in scalers.items():\n",
    "    original_data_dict[column] = scaler.inverse_transform(normalized_data_dict[column].reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 标定归一化前后数据\n",
    "# data_point = np.array([1500]).reshape(-1, 1)\n",
    "# data1 = scalers[output_term[0]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data1).reshape(-1, 1)\n",
    "# data2 = scalers[output_term[0]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array([1510]).reshape(-1, 1)\n",
    "# data3 = scalers[output_term[0]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data3).reshape(-1, 1)\n",
    "# data4 = scalers[output_term[0]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# print(data1)\n",
    "# print(data2)\n",
    "# print(data3)\n",
    "# print(data4)\n",
    "# print('每摄氏度的输出差：',(data3-data1)/(data4-data2))\n",
    "\n",
    "\n",
    "\n",
    "# data_point = np.array([0.5]).reshape(-1, 1)\n",
    "# data1 = scalers[output_term[1]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data1).reshape(-1, 1)\n",
    "# data2 = scalers[output_term[1]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array([0.6]).reshape(-1, 1)\n",
    "# data3 = scalers[output_term[1]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data3).reshape(-1, 1)\n",
    "# data4 = scalers[output_term[1]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# print(data1)\n",
    "# print(data2)\n",
    "# print(data3)\n",
    "# print(data4)\n",
    "# print('每0.01浓度的输出差：',(data3-data1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合训练数据--拆分训练、测试集\n",
    "test_size = 0.10\n",
    "def make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,test_size):\n",
    "    # 假设您有六个时间序列数据\n",
    "    # u1_data, u2_data, u3_data, u4_data, y1_data, y2_data 是形状为 (800, 1) 的 NumPy 数组\n",
    "\n",
    "    # 堆叠输入和输出数据\n",
    "    X = np.column_stack((u1_data, u2_data, u3_data, u4_data, y1_data, y2_data))\n",
    "    y = np.column_stack((y1_data, y2_data))\n",
    "    # print('X',X.shape)\n",
    "\n",
    "    # 定义时间步数和特征数\n",
    "    time_steps = 2\n",
    "    features = 6\n",
    "\n",
    "    # 创建空数组用于存储新的输入和输出数据\n",
    "    X_modified = []\n",
    "    y_modified = []\n",
    "    \n",
    "    # 生成新的输入和输出数据\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_sample = X[i:i + time_steps, :]\n",
    "        y_sample = y[i + time_steps, :]  # 取每个序列的第11个时刻作为输出\n",
    "        # print(i,i + time_steps,i + time_steps)\n",
    "        X_modified.append(X_sample)\n",
    "        y_modified.append(y_sample)\n",
    "\n",
    "    # 将列表转换为 NumPy 数组\n",
    "    X_modified = np.array(X_modified)\n",
    "    y_modified = np.array(y_modified)\n",
    "\n",
    "    # # 打印新数据的形状\n",
    "    # print(\"Modified Input Shape:\", X_modified.shape)\n",
    "    # print(\"Modified Output Shape:\", y_modified.shape)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_modified, y_modified, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=42, \n",
    "                                                        shuffle=True)\n",
    "                                                        # shuffle=False)\n",
    "    # 打印训练集和测试集的形状\n",
    "    print(\"X_train Shape:\", X_train.shape)\n",
    "    print(\"y_train Shape:\", y_train.shape)\n",
    "    print(\"X_test Shape:\", X_test.shape)\n",
    "    print(\"y_test Shape:\", y_test.shape)\n",
    "\n",
    "    # print(X,y)\n",
    "    # print(X_modified,y_modified)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型列数据\n",
    "u1_data = normalized_data_dict[input_term[0]][index_gaolu]\n",
    "u2_data = normalized_data_dict[input_term[1]][index_gaolu]\n",
    "u3_data = normalized_data_dict[input_term[2]][index_gaolu]\n",
    "u4_data = normalized_data_dict[input_term[3]][index_gaolu]\n",
    "y1_data = normalized_data_dict[output_term[0]][index_gaolu]\n",
    "y2_data = normalized_data_dict[output_term[1]][index_gaolu]\n",
    "num_samples = y2_data.shape[0]\n",
    "\n",
    "X_gaolu_train, X_gaolu_test,\\\n",
    "y_gaolu_train, y_gaolu_test = make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,\n",
    "                                        test_size=test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型列数据\n",
    "u1_data = normalized_data_dict[input_term[0]][index_predict]\n",
    "u2_data = normalized_data_dict[input_term[1]][index_predict]\n",
    "u3_data = normalized_data_dict[input_term[2]][index_predict]\n",
    "u4_data = normalized_data_dict[input_term[3]][index_predict]\n",
    "y1_data = normalized_data_dict[output_term[0]][index_predict]\n",
    "y2_data = normalized_data_dict[output_term[1]][index_predict]\n",
    "num_samples = y2_data.shape[0]\n",
    "\n",
    "\n",
    "# print('Oxygen_enrich_rate:', u1_data.shape)\n",
    "# print('Set_coal_amount:', u2_data.shape)\n",
    "# print('hot_wind_temp:', u3_data.shape)\n",
    "# print('hot_wind_presure:', u4_data.shape)\n",
    "# print('temp:', y1_data.shape)\n",
    "# print('Si_percent:', y2_data.shape)\n",
    "# print(num_samples)\n",
    "\n",
    "X_predict_train, X_predict_test,\\\n",
    "y_predict_train, y_predict_test = make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,\n",
    "                                        test_size=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(u1_data)\n",
    "# plt.plot(u2_data)\n",
    "# plt.plot(u3_data)\n",
    "# plt.plot(u4_data)\n",
    "# plt.plot(y1_data)\n",
    "# plt.plot(y2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MyRNNModel(torch.nn.Module):\n",
    "    def __init__(self,features_size,hidden_size,isbidirectional):\n",
    "        super(MyRNNModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=features_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=isbidirectional\n",
    "        )\n",
    "        if isbidirectional:\n",
    "            self.fc = nn.Linear(2 * hidden_size, 2)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        last_lstm_output = lstm_out[:, -1, :]\n",
    "        # print(last_lstm_output)\n",
    "        output = self.fc(last_lstm_output)\n",
    "        return output\n",
    "\n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "        squared_diff = torch.pow(y_true - y_pred, 2)\n",
    "        sum_squared_diff = torch.sum(squared_diff)\n",
    "        mse = sum_squared_diff / len(y_true)\n",
    "        return mse\n",
    "\n",
    "    def my_fit(self, X_train, y_train, epochs=1, batch_size=32, lr=0.001):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        loss_list = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                x_batch = torch.tensor(X_train[i:i+batch_size], dtype=torch.float32)\n",
    "                y_batch = torch.tensor(y_train[i:i+batch_size], dtype=torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(x_batch)\n",
    "                loss = self.custom_loss(y_batch, y_pred)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            average_epoch_loss = epoch_loss / (len(X_train) // batch_size + 1)\n",
    "            print(f'第 {epoch + 1}/{epochs} 轮, 误差: {average_epoch_loss:.4f}', end='\\r')\n",
    "            loss_list.append(average_epoch_loss)\n",
    "\n",
    "        return loss_list\n",
    "\n",
    "    def my_predict(self, X_test):\n",
    "        # 设置模型为评估模式，这会关闭 dropout 等层\n",
    "        self.eval()\n",
    "        # 将输入数据转换为张量，并设置 requires_grad=True\n",
    "        x_tensor = torch.tensor(X_test, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        # 获取模型的预测输出\n",
    "        y_pred = self(x_tensor)\n",
    "        # 保留预测值的梯度信息\n",
    "        y_pred.retain_grad()\n",
    "        # 返回预测结果和包含梯度信息的张量\n",
    "        return y_pred[:,0].detach().numpy(),y_pred[:,1].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立高炉模型实例\n",
    "features_size = 6\n",
    "hidden_size = 16\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "model_gaolu = MyRNNModel(features_size = features_size, \n",
    "                        hidden_size = hidden_size,\n",
    "                        isbidirectional=False)\n",
    "epoch_sum_gaolu = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型训练\n",
    "epoch_once = 200\n",
    "epoch_sum_gaolu = epoch_sum_gaolu+epoch_once\n",
    "loss_history = model_gaolu.my_fit(X_gaolu_train, y_gaolu_train, epochs=epoch_once, batch_size=64,lr = 0.002)\n",
    "\n",
    "print('\\nepoch_sum:',epoch_sum_gaolu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型预测\n",
    "y_pred_0,y_pred_1  = model_gaolu.my_predict(X_gaolu_test)\n",
    "# 计算 RMSE、MRE\n",
    "y_test = y_gaolu_test\n",
    "# y_test = y_test[:70]\n",
    "# y_pred_0 = y_pred_0[:70]\n",
    "# y_pred_1 = y_pred_1[:70]\n",
    "\n",
    "\n",
    "\n",
    "y_test_0 = scalers[output_term[0]].inverse_transform((y_test[:, 0]).reshape(-1, 1)).flatten()\n",
    "y_test_1 = scalers[output_term[1]].inverse_transform((y_test[:, 1]).reshape(-1, 1)).flatten()\n",
    "y_pred_0_inverse_transform = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_inverse_transform = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test_0, y_pred_0_inverse_transform))\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test_1, y_pred_1_inverse_transform))\n",
    "\n",
    "# 计算 \n",
    "mre_0 = np.mean(np.abs((y_test_0 - y_pred_0_inverse_transform) / y_test_0))\n",
    "mre_1 = np.mean(np.abs((y_test_1 - y_pred_1_inverse_transform) / y_test_1))\n",
    "\n",
    "# 打印结果\n",
    "# print(f\"输出0: RMSE: {rmse_0:.4f}, MRE: {mre_0:.4f}\")\n",
    "# print(f\"输出1: RMSE: {rmse_1:.4f}, MRE: {mre_1:.4f}\")\n",
    "print(f\"RMSE: {output_term[0]}: {rmse_0:.4f}, {output_term[1]}: {rmse_1:.4f}\")\n",
    "print(f\"MRE : {output_term[0]}: { mre_0:.4f}, {output_term[1]}: { mre_1:.4f}\")\n",
    "\n",
    "# plot_hit_rate_curve(y_test, y_pred_0, y_pred_1)\n",
    "\n",
    "\n",
    "output0 = y_test_0 - y_pred_0_inverse_transform\n",
    "output1 = y_test_1 - y_pred_1_inverse_transform\n",
    "\n",
    "# print(f\"误差分析0:平均值:{output0.std():.4f},方差:{output0.mean():.4f}\")\n",
    "# print(f\"误差分析1:平均值:{output1.std():.4f},方差:{output1.mean():.4f}\")\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_test_0,'r')\n",
    "plt.plot(y_pred_0_inverse_transform,'g')\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_test_1,'r')\n",
    "plt.plot(y_pred_1_inverse_transform,'g')\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "#\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(output0,'r-')\n",
    "plt.ylabel(output_term[0]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(output1,'g-')\n",
    "plt.ylabel(output_term[1]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建预测模型实例\n",
    "features_size = 6\n",
    "hidden_size = 64\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "model = MyRNNModel(features_size = features_size, \n",
    "                    hidden_size = hidden_size,\n",
    "                    isbidirectional=True)\n",
    "epoch_sum = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型训练\n",
    "epoch_once = 200\n",
    "epoch_sum = epoch_sum+epoch_once\n",
    "loss_history = model.my_fit(X_predict_train, y_predict_train, epochs=epoch_once, batch_size=128,lr = 0.002)\n",
    "print('\\nepoch_sum:',epoch_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型预测\n",
    "y_pred_0,y_pred_1  = model.my_predict(X_predict_test)\n",
    "\n",
    "# 计算 RMSE、MRE\n",
    "y_test = y_predict_test\n",
    "# y_test = y_test[:-1]\n",
    "# y_pred_0 = y_pred_0[1:]\n",
    "# y_pred_1 = y_pred_1[1:]\n",
    "\n",
    "y_test_0 = scalers[output_term[0]].inverse_transform((y_test[:, 0]).reshape(-1, 1)).flatten()\n",
    "y_test_1 = scalers[output_term[1]].inverse_transform((y_test[:, 1]).reshape(-1, 1)).flatten()\n",
    "y_pred_0_inverse_transform = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_inverse_transform = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test_0, y_pred_0_inverse_transform))\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test_1, y_pred_1_inverse_transform))\n",
    "\n",
    "# 计算 \n",
    "mre_0 = np.mean(np.abs((y_test_0 - y_pred_0_inverse_transform) / y_test_0))\n",
    "mre_1 = np.mean(np.abs((y_test_1 - y_pred_1_inverse_transform) / y_test_1))\n",
    "\n",
    "# 打印结果\n",
    "# print(f\"输出0: RMSE: {rmse_0:.4f}, MRE: {mre_0:.4f}\")\n",
    "# print(f\"输出1: RMSE: {rmse_1:.4f}, MRE: {mre_1:.4f}\")\n",
    "print(f\"RMSE: {output_term[0]}: {rmse_0:.4f}, {output_term[1]}: {rmse_1:.4f}\")\n",
    "print(f\"MRE : {output_term[0]}: { mre_0:.4f}, {output_term[1]}: { mre_1:.4f}\")\n",
    "\n",
    "# plot_hit_rate_curve(y_test, y_pred_0, y_pred_1)\n",
    "\n",
    "\n",
    "output0 = y_test_0 - y_pred_0_inverse_transform\n",
    "output1 = y_test_1 - y_pred_1_inverse_transform\n",
    "\n",
    "# print(f\"误差分析0:平均值:{output0.std():.4f},方差:{output0.mean():.4f}\")\n",
    "# print(f\"误差分析1:平均值:{output1.std():.4f},方差:{output1.mean():.4f}\")\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_test_0,'r')\n",
    "plt.plot(y_pred_0_inverse_transform,'g')\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_test_1,'r')\n",
    "plt.plot(y_pred_1_inverse_transform,'g')\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "#\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(output0,'r-')\n",
    "plt.ylabel(output_term[0]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(output1,'g-')\n",
    "plt.ylabel(output_term[1]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0,y_pred_1  = model.my_predict(X_predict_test)\n",
    "y_pred_0_predict = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_predict = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "y_pred_0,y_pred_1  = model_gaolu.my_predict(X_predict_test)\n",
    "y_pred_0_gaolu = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_gaolu = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_pred_0_predict)\n",
    "plt.plot(y_pred_0_gaolu)\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_pred_1_predict)\n",
    "plt.plot(y_pred_1_gaolu)\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(y_pred_0_predict-y_pred_0_gaolu)\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(y_pred_1_predict-y_pred_1_gaolu)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
