{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 库文件\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import gp_minimize\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 Excel 文件读取数据\n",
    "df = pd.read_excel('data.xlsx')\n",
    "\n",
    "# 提取列数据\n",
    "u1_data = df['u1'].values\n",
    "u2_data = df['u2'].values\n",
    "y1_data = df['y1'].values\n",
    "y2_data = df['y2'].values\n",
    "\n",
    "# # 输出提取的数据\n",
    "# print('u1_data:', u1_data.shape)\n",
    "# print('u2_data:', u2_data.shape)\n",
    "# print('y1_data:', y1_data.shape)\n",
    "# print('y2_data:', y1_data.shape)\n",
    "\n",
    "num_samples = y1_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合训练数据  多输入双输出\n",
    "# 假设有训练数据 u1_data, u2_data, y1_data 和 y1_data+1\n",
    "# 将它们组合成输入特征矩阵 X 和输出标签向量 y\n",
    "# 1 |2| 3 4 5 6 \n",
    "# 6 |1| 2 3 4 5\n",
    "# 1 |2| 3 4 5 6 \n",
    "\n",
    "u1_data = u1_data\n",
    "u2_data = u2_data\n",
    "\n",
    "u1_data_1 = np.roll(u1_data, 1)\n",
    "u2_data_1 = np.roll(u2_data, 1)\n",
    "u1_data_1[0], u2_data_1[0] = 0, 0\n",
    "\n",
    "y1_data = y1_data\n",
    "y2_data = y2_data\n",
    "\n",
    "X = np.column_stack((   u1_data  [1:-1], u2_data  [1:-1],\n",
    "                        u1_data_1[1:-1], u2_data_1[1:-1],\n",
    "                        y1_data  [1:-1], y2_data  [1:-1])\n",
    "                    )\n",
    "y = np.column_stack((y1_data[2:],y2_data[2:]))\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3333333, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型参数\n",
    "def get_params(W_b):\n",
    "\n",
    "    mid_indix = W_b.shape[0]//2-1\n",
    "    pred_0 = W_b[-2:-1]\n",
    "    W0 = W_b[:mid_indix]\n",
    "    b1 = W_b[-1:]\n",
    "    W1 = W_b[mid_indix:mid_indix*2]\n",
    "    W_b_0 = np.concatenate((W0, pred_0))\n",
    "    W_b_1 = np.concatenate((W1, b1))\n",
    "    # print(mid_indix)\n",
    "\n",
    "    # print('pred_0:',pred_0.shape)\n",
    "    # print('W0:',W0.shape)\n",
    "    # print('b1:',b1.shape)\n",
    "    # print('W1:',W1.shape)\n",
    "    return pred_0,W0,b1,W1,W_b_0,W_b_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义My_LS_SVRModel\n",
    "class My_M_LS_SVRModel:\n",
    "    def __init__(self, params):\n",
    "        C0, C1, C00, gamma= params\n",
    "        self.C0 = C0\n",
    "        self.C1 = C1\n",
    "        self.C00 = C00\n",
    "        self.gamma = gamma\n",
    "        self.W_b = None\n",
    "        self.X_train = None\n",
    "\n",
    "    def model_train(self, X_train, y_train, K_train):\n",
    "        def objective(W_b, X, y):\n",
    "            b0,W0,b1,W1,W_b_0,W_b_1 = get_params(W_b)\n",
    "\n",
    "            y_pred_0 = np.dot(K_train, W0) + b0\n",
    "            y_pred_1 = np.dot(K_train, W1) + b1\n",
    "            errors0 = y[:,0] - y_pred_0\n",
    "            errors1 = y[:,1] - y_pred_1\n",
    "\n",
    "            # 损失函数\n",
    "            loss = ( 0.5 * (np.dot(W0, W0)+np.dot(W1, W1)) \n",
    "                    + self.C0 * np.sum(errors0**2) + self.C1 * np.sum(errors1**2)\n",
    "                    # + C00 * np.sum(np.sqrt(errors0**2 + errors1**2)) # L2 范数\n",
    "                    + self.C00 * np.sum(errors0**2 + errors1**2) # L2 范数的平方\n",
    "                    )\n",
    "            return loss\n",
    "\n",
    "        # 初始化权重向量+偏移项b\n",
    "        initial_W_b = np.zeros((X_train.shape[0])*2+(1)*2)\n",
    "\n",
    "        # 使用minimize 函数最小化目标函数\n",
    "        result = minimize(objective, initial_W_b, args=(X_train, y_train),\n",
    "                            method='L-BFGS-B')\n",
    "        # 输出最优的权重向量\n",
    "        best_W_b = result.x\n",
    "        return best_W_b\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        K_train = rbf_kernel(X_train, X_train, gamma=self.gamma)\n",
    "        self.W_b = self.model_train(X_train, y_train, K_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        b0,W0,b1,W1,W_b_0,W_b_1 = get_params(self.W_b)\n",
    "        K_test = rbf_kernel(X_test, self.X_train, gamma=self.gamma)\n",
    "        y_pred_0 = np.dot(K_test, W0) + b0\n",
    "        y_pred_1 = np.dot(K_test, W1) + b1\n",
    "        return y_pred_0, y_pred_1\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# # 示例用法\n",
    "# params = [8.78525340e+01, 2.01347249e-03]\n",
    "# # 创建模型\n",
    "# my_svr_model = My_LS_SVRModel(params=params)\n",
    "# # 训练模型\n",
    "# my_svr_model.fit(X_train, y_train)\n",
    "# # 模型预测\n",
    "# y_pred = my_svr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 粒子群参数设置\n",
    "Particle_num = 100\n",
    "iterations_max=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 粒子群优化\n",
    "def initialize_particles(Particle_num, params_num, Xmin, Xmax, Vmin, Vmax):\n",
    "    # 初始化粒子群的位置和速度\n",
    "    positions = np.random.uniform(Xmin, Xmax, size=(Particle_num, params_num))\n",
    "    # plt.plot(positions[:,0],positions[:,1])\n",
    "    velocities = np.random.uniform(Vmin, Vmax, size=(Particle_num, params_num))\n",
    "    return positions, velocities\n",
    "def evaluate_fitness(positions, fitness_values, X_train, y_train, X_test, y_test):\n",
    "    # 在这里计算适应值（均方根误差）\n",
    "    fitness_values = your_fitness_function(positions, fitness_values, X_train, y_train, X_test, y_test)\n",
    "    return fitness_values\n",
    "def update_personal_best(personal_best_positions, personal_best_fitness, positions, fitness_values):\n",
    "    # 对每个粒子进行循环\n",
    "    for i in range(len(positions)):\n",
    "        # 如果当前适应值更好，则更新个体最佳位置和适应值\n",
    "        if fitness_values[i] < personal_best_fitness[i]:\n",
    "            personal_best_positions[i] = positions[i].copy()\n",
    "            personal_best_fitness[i] = fitness_values[i]\n",
    "    return personal_best_positions, personal_best_fitness\n",
    "def update_global_best(global_best_position, global_best_fitness, personal_best_positions, personal_best_fitness):\n",
    "    # 找到所有粒子中适应值最好的粒子的索引\n",
    "    best_particle_index = np.argmin(personal_best_fitness)\n",
    "    # 如果该粒子的适应值更好，则更新全局最佳位置和适应值\n",
    "    if personal_best_fitness[best_particle_index] < global_best_fitness:\n",
    "        global_best_position[:] = personal_best_positions[best_particle_index].copy()\n",
    "        global_best_fitness = personal_best_fitness[best_particle_index]\n",
    "    return global_best_position,global_best_fitness\n",
    "def update_particles(iteration, iterations_max, positions, velocities, personal_best_positions, global_best_position, \n",
    "                    c1, c2, Xmin, Xmax, Vmin, Vmax):\n",
    "    # 更新粒子的速度和位置\n",
    "    r1 = np.random.rand(*positions.shape)\n",
    "    r2 = np.random.rand(*positions.shape)\n",
    "    \n",
    "    w_max = 0.9\n",
    "    w_min = 0.4\n",
    "    weight = w_max - iteration*(w_max-w_min)/iterations_max\n",
    "    # weight = 1\n",
    "    velocities = weight * velocities + c1 * r1 * (personal_best_positions - positions) + c2 * r2 * (global_best_position - positions)\n",
    "    # 限制速度范围\n",
    "    velocities = np.clip(velocities, Vmin, Vmax)\n",
    "    # 更新位置\n",
    "    positions = positions + velocities\n",
    "    # 限制位置范围\n",
    "    positions = np.clip(positions, Xmin, Xmax)\n",
    "\n",
    "    return positions, velocities\n",
    "def pso_algorithm(Particle_num, Xmin, Xmax, Vmin, Vmax, iterations_max, params_num, C1, C2, tao, X_train, y_train, X_test, y_test):\n",
    "    # 初始化粒子群\n",
    "    positions, velocities = initialize_particles(Particle_num, params_num, Xmin, Xmax, Vmin, Vmax)\n",
    "\n",
    "    # 初始化每个粒子的个体最佳位置和适应值\n",
    "    personal_best_positions = positions.copy()\n",
    "    personal_best_fitness = np.full(Particle_num, np.inf)#所有元素的值都设置为正无穷\n",
    "    \n",
    "    # 初始化全局最佳位置和适应值\n",
    "    global_best_position = np.zeros(params_num)\n",
    "    global_best_fitness = np.inf\n",
    "\n",
    "    fitness_values = np.zeros(Particle_num)\n",
    "    # 开始迭代\n",
    "    fitness_values_list = []  # 用于存储每次迭代后的最佳适应值\n",
    "    for iteration in range(iterations_max):\n",
    "        print('iteration',iteration)\n",
    "        # 计算每个粒子的适应值\n",
    "        fitness_values = evaluate_fitness(positions, fitness_values, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # 更新个体最佳位置和适应值\n",
    "        personal_best_positions, personal_best_fitness = update_personal_best(personal_best_positions, personal_best_fitness, positions, fitness_values)\n",
    "        \n",
    "        # 更新全局最佳位置和适应值\n",
    "        global_best_position,global_best_fitness = update_global_best(global_best_position, global_best_fitness, personal_best_positions, personal_best_fitness)\n",
    "        print(global_best_position,global_best_fitness)\n",
    "        # 更新粒子的速度和位置\n",
    "        positions, velocities = update_particles(iteration, iterations_max,positions, velocities, personal_best_positions, global_best_position, C1, C2, Xmin, Xmax, Vmin, Vmax)\n",
    "        \n",
    "        # 记录适应度值\n",
    "        fitness_values_list.append(global_best_fitness)\n",
    "        \n",
    "        # 检查收敛精度\n",
    "        if global_best_fitness < tao:\n",
    "            break\n",
    "\n",
    "    # 返回最终的全局最佳位置和适应值\n",
    "    return global_best_position, global_best_fitness, fitness_values_list\n",
    "# 替换为你实际的目标函数\n",
    "def your_fitness_function(positions, fitness_values, X_train, y_train, X_test, y_test):\n",
    "    for i in range(len(positions)):\n",
    "        # 示例用法\n",
    "        params = positions[i]\n",
    "        # 创建模型\n",
    "        my_svr_model = My_M_LS_SVRModel(params=params)\n",
    "        # 训练模型\n",
    "        my_svr_model.fit(X_train, y_train)\n",
    "        # 模型预测\n",
    "        y_pred_0, y_pred_1 = my_svr_model.predict(X_test)        \n",
    "        # 在这里计算适应值（均方根误差）\n",
    "        errors0 = y_test[:,0] - y_pred_0\n",
    "        errors1 = y_test[:,1] - y_pred_1\n",
    "        mse = np.sqrt(np.sum(errors0**2+errors1**2)/X_test.shape[0])\n",
    "        fitness_values[i] = mse\n",
    "\n",
    "        print('i',i,\"mse\",mse,\"position\",params)\n",
    "    return fitness_values\n",
    "\n",
    "\n",
    "\n",
    "# position = [C0, C1, C00, gamma]\n",
    "# 调用粒子群算法\n",
    "vel = 1\n",
    "Xmin = [0]\n",
    "Xmax = [100]\n",
    "result_position, result_fitness, fitness_values_list = pso_algorithm(Particle_num = Particle_num, Xmin=Xmin, Xmax=Xmax, Vmin=-vel, Vmax=vel, \n",
    "                                                iterations_max = iterations_max, params_num = 4, C1=2, C2=2, tao=0.1, \n",
    "                                                X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Global Best Position and Fitness: {result_position}  {result_fitness}\")\n",
    "\n",
    "plt.plot(fitness_values_list)\n",
    "plt.figure(figsize=(10, 6))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化曲线\n",
    "print(f\"Global Best Position and Fitness: {result_position}  {result_fitness}\")\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(fitness_values_list, label='fitness_values')\n",
    "# plt.xlabel('iteration Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "plt.plot(fitness_values_list[30:])\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 差分方程  # 生成数据\n",
    "def nonlinear_system(y1_k, y2_k, u1_k, u2_k, u1_k_1, u2_k_1):\n",
    "    # 生成噪声\n",
    "    noise_level = 0.01\n",
    "    noise1 = np.random.normal(loc=0, scale=np.sqrt(noise_level))\n",
    "    noise2 = np.random.normal(loc=0, scale=np.sqrt(noise_level))\n",
    "    # 计算输出\n",
    "    output1 = y1_k / (1 + y2_k**2) + u1_k + 0.2 * u2_k + 0.4 * u1_k_1 + 0.1 * u2_k_1 \n",
    "    output2 = y1_k * y2_k / (1 + y2_k**2) + 0.3 * u1_k + u2_k + 0.1 * u1_k_1 + 0.5 * u2_k_1\n",
    "    # return output1 + noise1, output2 + noise2\n",
    "    return output1 + noise1, output2 + noise2 ,noise1 ,noise2\n",
    "    # return output1, output2,noise1,noise2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "#  data  [23.65353603, 46.24063272, 14.1795326,   0.14215454]  0.29159782217670577\n",
    "#  data2  [36.82522053 53.21374946 18.48987828  0.15809682]  0.5322094851234387\n",
    "#  [11.16 ,10.23 ,9.64,  0.09] \n",
    "#  [11.16 ,10.23 ,9.64,  ,0.07922554]\n",
    "params =    [49.55154183 ,66.64849594 ,28.47570688  ,0.07922554]\n",
    "my_svr_model = My_M_LS_SVRModel(params=params)\n",
    "# 训练模型\n",
    "my_svr_model.fit(X_train, y_train)\n",
    "# 模型预测\n",
    "y_pred_0, y_pred_1 = my_svr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 RMSE、MRE、画出误差的概率密度函数\n",
    "y_test = y_test\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test[:, 0], y_pred_0))\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test[:, 1], y_pred_1))\n",
    "\n",
    "# 计算 \n",
    "mre_0 = np.mean(np.abs((y_test[:, 0] - y_pred_0) / y_test[:, 0])) * 100\n",
    "mre_1 = np.mean(np.abs((y_test[:, 1] - y_pred_1) / y_test[:, 1])) * 100\n",
    "\n",
    "# 打印结果\n",
    "print(\"Dimension 0:\")\n",
    "print(\"RMSE:\", rmse_0)\n",
    "print(\"MRE:\", mre_0)\n",
    "\n",
    "print(\"\\nDimension 1:\")\n",
    "print(\"RMSE:\", rmse_1)\n",
    "print(\"MRE:\", mre_1)\n",
    "\n",
    "# 假设 error0 和 error1 是你的误差数据，这里使用随机生成的数据作为示例\n",
    "error0 = y_test[:, 0]-y_pred_0\n",
    "error1 = y_test[:, 1]-y_pred_1\n",
    "\n",
    "# 计算误差的概率密度函数\n",
    "plt.hist(error0, bins=20, density=True, alpha=0.6, color='g', label='Error 0')\n",
    "plt.hist(error1, bins=20, density=True, alpha=0.6, color='b', label='Error 1')\n",
    "\n",
    "# 生成 PDF 的 x 值范围\n",
    "x_range = np.linspace(min(min(error0), min(error1)), max(max(error0), max(error1)), 10000)\n",
    "\n",
    "# 计算正态分布的概率密度函数\n",
    "pdf_values0 = 1/(np.sqrt(2*np.pi)*np.std(error0)) * np.exp(-(x_range-np.mean(error0))**2/(2*np.std(error0)**2))\n",
    "pdf_values1 = 1/(np.sqrt(2*np.pi)*np.std(error1)) * np.exp(-(x_range-np.mean(error1))**2/(2*np.std(error1)**2))\n",
    "\n",
    "# 绘制正态分布的概率密度函数\n",
    "plt.plot(x_range, pdf_values0, 'k-', linewidth=2, label='PDF 0')\n",
    "plt.plot(x_range, pdf_values1, 'm-', linewidth=2, label='PDF 1')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Error Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Error PDF Comparison')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果及误差\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(y_test[:, 0], 'r-', label='y_test')\n",
    "plt.plot(y_pred_0, 'b-', label='y_pred')\n",
    "\n",
    "plt.ylabel('y1')\n",
    "plt.title('Comparison of y_test and y_pred (Dimension 0)')\n",
    "plt.legend()\n",
    "\n",
    "# 在每隔五个样本的位置画竖直虚线\n",
    "for i in range(4, len(y_test), 5):\n",
    "    plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(y_test[:, 1], 'r-', label='y_test')\n",
    "plt.plot(y_pred_1, 'b-', label='y_pred')\n",
    "\n",
    "plt.ylabel('y2')\n",
    "plt.title('Comparison of y_test and y_pred (Dimension 1)')\n",
    "plt.legend()\n",
    "\n",
    "# 在每隔五个样本的位置画竖直虚线\n",
    "for i in range(4, len(y_test), 5):\n",
    "    plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果及误差\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_test[:, 0], 'r-', label='y_test')\n",
    "plt.plot(y_pred_0, 'b-', label='y_pred')\n",
    "\n",
    "plt.ylabel('y1')\n",
    "plt.title('Comparison of y_test and y_pred (Dimension 0)')\n",
    "plt.legend()\n",
    "\n",
    "# 在每隔五个样本的位置画竖直虚线\n",
    "for i in range(4, len(y_test), 5):\n",
    "    plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_test[:, 1], 'r-', label='y_test')\n",
    "plt.plot(y_pred_1, 'b-', label='y_pred')\n",
    "\n",
    "plt.ylabel('y2')\n",
    "plt.title('Comparison of y_test and y_pred (Dimension 1)')\n",
    "plt.legend()\n",
    "\n",
    "# 在每隔五个样本的位置画竖直虚线\n",
    "for i in range(4, len(y_test), 5):\n",
    "    plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(y_test[:, 0]-y_pred_0, 'ro-', label='err')\n",
    "\n",
    "plt.ylabel('y1_err')\n",
    "plt.title('Error of y_test , y_pred (Dimension 0)')\n",
    "plt.legend()\n",
    "\n",
    "# 在每隔五个样本的位置画竖直虚线\n",
    "for i in range(4, len(y_test), 5):\n",
    "    plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(y_test[:, 1]-y_pred_1, 'ro-', label='err')\n",
    "\n",
    "plt.ylabel('y2_err')\n",
    "plt.title('Error of y_test , y_pred (Dimension 1)')\n",
    "plt.legend()\n",
    "\n",
    "# 在每隔五个样本的位置画竖直虚线\n",
    "for i in range(4, len(y_test), 5):\n",
    "    plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结构命中率曲线\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 计算 error0 和 error1 的绝对值小于阈值的比例\n",
    "thresholds = np.linspace(0, 1, 50)  # 设置不同的阈值\n",
    "below_threshold_percentages_0 = []\n",
    "below_threshold_percentages_1 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    error0_abs = np.abs(y_test[:, 0] - y_pred_0)\n",
    "    below_threshold_percentage_0 = np.mean(error0_abs < threshold)\n",
    "    below_threshold_percentages_0.append(below_threshold_percentage_0)\n",
    "\n",
    "    error1_abs = np.abs(y_test[:, 1] - y_pred_1)\n",
    "    below_threshold_percentage_1 = np.mean(error1_abs < threshold)\n",
    "    below_threshold_percentages_1.append(below_threshold_percentage_1)\n",
    "\n",
    "# 找到几个关键点的坐标\n",
    "key_points_thresholds = [0.1, 0.2, 0.3]\n",
    "key_points_percentages_0 = [below_threshold_percentages_0[np.argmin(np.abs(thresholds - t))] for t in key_points_thresholds]\n",
    "key_points_percentages_1 = [below_threshold_percentages_1[np.argmin(np.abs(thresholds - t))] for t in key_points_thresholds]\n",
    "\n",
    "# 绘制两个子图\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 第一个子图，绘制 error0\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(thresholds, below_threshold_percentages_0, 'b-')\n",
    "plt.scatter(key_points_thresholds, key_points_percentages_0, color='red', marker='o')  # 添加关键点\n",
    "\n",
    "# 添加关键点的标签并调整位置\n",
    "for threshold, percentage in zip(key_points_thresholds, key_points_percentages_0):\n",
    "    plt.annotate(f'({threshold:.2f}, {percentage:.2%})', xy=(threshold, percentage), xytext=(threshold + 0.1, percentage + 0.01),\n",
    "                arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "\n",
    "plt.title('Dimension 0')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend()\n",
    "\n",
    "# 第二个子图，绘制 error1\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(thresholds, below_threshold_percentages_1, 'g-')\n",
    "plt.scatter(key_points_thresholds, key_points_percentages_1, color='red', marker='o')  # 添加关键点\n",
    "\n",
    "# 添加关键点的标签并调整位置\n",
    "for threshold, percentage in zip(key_points_thresholds, key_points_percentages_1):\n",
    "    plt.annotate(f'({threshold:.2f}, {percentage:.2%})', xy=(threshold, percentage), xytext=(threshold + 0.1, percentage + 0.01),\n",
    "                arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "\n",
    "plt.title('Dimension 1')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend()\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成期望数据\n",
    "Times = 100\n",
    "\n",
    "def generate_y_aim_data(Times):\n",
    "    set_y1 = np.full(Times, 0.4)\n",
    "    set_y1[40:] = 0.6\n",
    "    # set_y1[90:] = -0.1\n",
    "    # set_y1[130:151] = 0.0\n",
    "    # set_y1[170:201] = 0.4\n",
    "    # set_y1[185] = -0.7  # 添加脉冲干扰\n",
    "\n",
    "    set_y2 = np.full(Times, 0.2)\n",
    "    set_y2[70:] = 0.3\n",
    "    # set_y2[90:] = 0.5\n",
    "    # set_y2[150:] = -0.7  # 添加脉冲干扰\n",
    "    # set_y2[200:] = 0.4\n",
    "\n",
    "    # 限制设定值在 -1 到 1 之间\n",
    "    # set_y1 = np.clip(set_y1, -1, 1)\n",
    "    # set_y2 = np.clip(set_y2, -1, 1)\n",
    "\n",
    "    return set_y1, set_y2\n",
    "\n",
    "\n",
    "\n",
    "# # 调用示例\n",
    "# set_y1, set_y2 = generate_y_aim_data(Times)\n",
    "# plt.plot(set_y1)\n",
    "# plt.plot(set_y2)\n",
    "# plt.title('y_sp')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成参考轨迹\n",
    "def get_yr(aim_value,current_value,alpha,P):\n",
    "    # 生成设定信号\n",
    "    setpoint_signal = np.full(10, aim_value)\n",
    "    # 初始化参数\n",
    "    alpha = alpha\n",
    "    y_r = np.zeros(P)\n",
    "    y_r[0] = current_value\n",
    "    # 模拟一阶模型\n",
    "    for k in range(1,P):\n",
    "        y_r[k] = alpha * y_r[k-1] + (1 - alpha) * aim_value\n",
    "\n",
    "    # # 绘制结果\n",
    "    # plt.plot(setpoint_signal, label='Setpoint Signal')\n",
    "    # plt.plot(y_r,'o-', label='Output Signal (Tracked)')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Time')\n",
    "    # plt.ylabel('Amplitude')\n",
    "    # plt.title('Tracking Setpoint Signal with One-Order Model')\n",
    "    # plt.show()\n",
    "    return y_r\n",
    "# 测试\n",
    "y_r = get_yr(1,-0.5,0.667,5+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成控制时域的数据格式\n",
    "def generate_k_data(u1_data, u2_data, y1_data, num_samples, P):\n",
    "    # 生成随机索引值\n",
    "    #从原有数据的randint时刻开始往下进行控制\n",
    "    randint = np.random.randint(1, num_samples - 2 - P - 1)\n",
    "    randint = 181  # 如果你希望使用固定的值而不是随机生成\n",
    "    # randint = 250  # 如果你希望使用固定的值而不是随机生成\n",
    "    print(randint)\n",
    "    # 提取数据并构成 k_data\n",
    "    # 第一次得到下面五个变量，固定好格式构成k_data\n",
    "    u1   = u1_data[randint  :randint+2  ]\n",
    "    u2   = u2_data[randint  :randint+2  ]\n",
    "    u1_1 = u1_data[randint-1:randint+2-1]\n",
    "    u2_1 = u2_data[randint-1:randint+2-1]\n",
    "    y1   = y1_data[randint  :randint+2  ]\n",
    "    y2   = y2_data[randint  :randint+2  ]\n",
    "    k_data = np.concatenate((u1, u2, u1_1, u2_1, y1, y2), axis=0)\n",
    "    # print(k_data.shape)\n",
    "\n",
    "    k_data = np.zeros_like(k_data)\n",
    "    return k_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_weights(length, decay_factor=0.9):\n",
    "    \"\"\"\n",
    "    生成指数衰减的权重数组。\n",
    "\n",
    "    Parameters:\n",
    "    - length: 权重数组的长度\n",
    "    - decay_factor: 衰减因子，控制权重的衰减速度\n",
    "\n",
    "    Returns:\n",
    "    - weights: 生成的权重数组\n",
    "    \"\"\"\n",
    "    weights = np.power(decay_factor, np.arange(length))\n",
    "    weights /= np.sum(weights)  # 归一化确保权重之和为1\n",
    "    return weights\n",
    "def loss_function(original_sequence, simulated_sequence, weights):\n",
    "    \"\"\"\n",
    "    计算原始序列和仿真预测序列的加权误差损失函数。\n",
    "\n",
    "    Parameters:\n",
    "    - original_sequence: 原始序列\n",
    "    - simulated_sequence: 仿真预测序列\n",
    "    - weights: 用于加权的权重数组\n",
    "\n",
    "    Returns:\n",
    "    - weighted_loss: 加权误差损失\n",
    "    \"\"\"\n",
    "    error = original_sequence - simulated_sequence\n",
    "    weighted_loss = np.dot(weights, np.square(error))\n",
    "    return weighted_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义单时刻的MPC问题优化\n",
    "def my_MPC(k_data,params,M,P,y1_aim,y2_aim):\n",
    "    # 从固定格式k_data里面读取信息\n",
    "    u1   = k_data[0:2]\n",
    "    u2   = k_data[2:4]\n",
    "    u1_1 = k_data[4:6]\n",
    "    u2_1 = k_data[6:8]\n",
    "    y1   = k_data[8:10]\n",
    "    y2   = k_data[10:12]\n",
    "    # 获取猜测值[h U1 U2]\n",
    "    # h, U1, U2  =params[0], params[1:M+1],params[M+1:]\n",
    "    U1, U2  =params[0:M], params[M:2*M]\n",
    "    h = 1.0\n",
    "    # 整理数据见   MPC推到.escel\n",
    "    u1   = np.concatenate((u1[:1],U1))\n",
    "    u2   = np.concatenate((u2[:1],U2))\n",
    "    u1_1 = np.concatenate((u1_1[:2],U1[:-1]))\n",
    "    u2_1 = np.concatenate((u2_1[:2],U2[:-1]))\n",
    "    y1   = np.concatenate((y1,np.zeros(P)))\n",
    "    y2   = np.concatenate((y2,np.zeros(P)))\n",
    "    y1_k = y1[1]\n",
    "    y2_k = y2[1]\n",
    "    # print(u1)\n",
    "    # print(u2)\n",
    "    # print(u1_1)\n",
    "    # print(u2_1)\n",
    "    # print(y1)\n",
    "    # print(y2)\n",
    "    # print(y1_k)    \n",
    "    # print(y2_k)\n",
    "    # 生成指数衰减的权重\n",
    "    weights = exponential_decay_weights(P, decay_factor=0.67)\n",
    "\n",
    "    # 总共预测 P+1 次\n",
    "    # 对k时刻进行预测-----1次\n",
    "    for j in range(1):\n",
    "        x = np.column_stack((u1[j],u2[j],u1_1[j],u2_1[j],y1[j],y2[j]))\n",
    "        y1_m_k,y2_m_k = my_svr_model.predict(x)\n",
    "        # y1[j+1] = y1_m_k.item()###############################是否替换不知道有没有影响？\n",
    "        # y2[j+1] = y2_m_k.item()###############################\n",
    "        # 在k时刻，我要先通过k-1时刻来预测出当前k时刻下的预测值。\n",
    "        # 实际上，这个时候我有k时刻的真实值。\n",
    "        # 但是这么做是为了能够获取我的预测值和真实值之间的误差，\n",
    "        # 然后基于这个误差，通过对控制器输入的调整来预测k+1时刻，\n",
    "        # 然后依次往下。因此，在k时刻，我系统的值是固定的，\n",
    "        # 也就是我的真实值，所以我要把它存储到我的整体的一个序列里面。\n",
    "        # 在取出当前k时刻真实值的过程中，我不能将之前预测的时候的那个\n",
    "        # 预测值覆盖掉真实值。后面新预测的数值要加上前面的那一个误差\n",
    "        E1_k = y1_k - y1_m_k\n",
    "        E2_k = y2_k - y2_m_k\n",
    "\n",
    "    # 对每个U对应的控制时刻进行预测-----M次\n",
    "    for j in range(1,M+1):  \n",
    "        x = np.column_stack((u1[j],u2[j],u1_1[j],u2_1[j],y1[j],y2[j]))\n",
    "        y1_k_j,y2_k_j = my_svr_model.predict(x)\n",
    "        y1[j+1] = y1_k_j.item()#将预测值作为下一步的输出值\n",
    "        y2[j+1] = y2_k_j.item()\n",
    "\n",
    "    # 对控制时域外的部分进行预测-----P-M次\n",
    "    # 注意：这部分的信号是保持控制不变下进行\n",
    "    for j in range(M+1,P+1):\n",
    "        x = np.column_stack((u1[-1],u2[-1],u1[-1],u2[-1],y1[j],y2[j]))\n",
    "        y1_k_j,y2_k_j = my_svr_model.predict(x)\n",
    "        y1[j+1] = y1_k_j.item()#将预测值作为下一步的输出值\n",
    "        y2[j+1] = y2_k_j.item()\n",
    "\n",
    "    # print(u1)\n",
    "    # print(u2)\n",
    "    # print(u1_1)\n",
    "    # print(u2_1)\n",
    "    # print(y1)\n",
    "    # print(y2)\n",
    "    # print(y1_k)    \n",
    "    # print(y2_k)\n",
    "    # print('2222222222222222222')\n",
    "        \n",
    "\n",
    "    #和获取参考轨迹\n",
    "    # 一定要对照好做差的序列\n",
    "    y_r  = get_yr(y1_aim,y1_k,0.1,P+1)\n",
    "    y1_r = y_r[1:] \n",
    "    # print('y1_aim',y1_aim)\n",
    "    # print('y_r',y_r)\n",
    "\n",
    "\n",
    "    y_r  = get_yr(y2_aim,y2_k,0.1,P+1)\n",
    "    y2_r = y_r[1:] \n",
    "    # print('y2_aim',y2_aim)\n",
    "    # print('y_r',y_r)\n",
    "\n",
    "    y1_M_k = y1[2:]\n",
    "    y2_M_k = y2[2:]\n",
    "    # print('y1',y1)\n",
    "    # print('h*E1_k',h*E1_k)\n",
    "    # print('y2',y2)\n",
    "    # print('h*E2_k',h*E2_k)\n",
    "\n",
    "\n",
    "\n",
    "    # 计算mse\n",
    "    # lamda1太大的话会导致y1_r和y1_M_k的误差加大*****************导致超调的原因\\与目标值之间存在间隙\n",
    "    lamda1 = 0.0\n",
    "    lamda2 = 0.0\n",
    "    if np.abs(y1_aim-y1_k)<0.0001 and np.abs(y2_aim-y2_k)<0.0001:\n",
    "        lamda1 = 1\n",
    "        lamda2 = 1\n",
    "    mse = (0\n",
    "            # +loss_function(y1_r, y1_M_k+h*E1_k, weights)\n",
    "            # +loss_function(y2_r, y2_M_k+h*E2_k, weights)\n",
    "            # +(np.abs(y1_aim-y1_k)**2+np.abs(y2_aim-y2_k)**2)*P*2000\n",
    "            +np.sum((y1_r-y1_M_k-h*E1_k)**2 + (y2_r-y2_M_k-h*E2_k)**2)\n",
    "            +np.sum(lamda1*(np.diff(u1)**2))\n",
    "            +np.sum(lamda2*(np.diff(u2)**2))\n",
    "\n",
    "\n",
    "            )\n",
    "\n",
    "    k_data2 = np.concatenate((u1[1:3],u2[1:3],u1_1[1:3],u2_1[1:3],y1[1:3],y2[1:3]),axis=0)\n",
    "\n",
    "    return mse , k_data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对未来Times周期预测控制\n",
    "# 期望设定值\n",
    "set_y1 , set_y2 = generate_y_aim_data(Times)\n",
    "# MPC参数\n",
    "P = 3  # 预测时域长度\n",
    "M = 2  # 控制时域长度\n",
    "#生成控制时域的数据格式\n",
    "k_data = generate_k_data(u1_data, u2_data, y1_data, num_samples, P)\n",
    "\n",
    "# MPC控制循环   迭代的只有：k_data\n",
    "all_pred_y1 = []\n",
    "all_pred_y2 = []\n",
    "all_pred_u1 = []\n",
    "all_pred_u2 = []\n",
    "all_pred_noise1  = []\n",
    "all_pred_noise2 = []\n",
    "# all_pred_y1.append(y1_data[1])\n",
    "# all_pred_y2.append(y2_data[1])\n",
    "# MPC控制循环\n",
    "for k in range(Times):\n",
    "    print(f\"这是对第{k}时刻的最优U1、U2输入求解\")\n",
    "    # print('y1_aim  y2_aim',set_y1[k],set_y2[k])\n",
    "    # 定义优化目标函数\n",
    "    def objective_function(params, *k_data):\n",
    "        mse, k_data2 = my_MPC(k_data=k_data[0], params=params, M=M, P=P, y1_aim = set_y1[k], y2_aim = set_y2[k])  \n",
    "        return mse\n",
    "\n",
    "    # # 初始猜测值[h U1 U2]\n",
    "    # params = np.concatenate([np.array([0.1]), np.ones(M), np.ones(M)])\n",
    "    # # 定义参数的上下限  \n",
    "    # bounds = [(0, 1)] + [(-1, 1) for _ in range(2 * M)]\n",
    "\n",
    "    # 初始猜测值[h U1 U2]\n",
    "    params = np.concatenate([np.ones(M), np.ones(M)])\n",
    "    # 定义参数的上下限  \n",
    "    bounds = [(-1, 1) for _ in range(2 * M)]\n",
    "    # 进行优化\n",
    "    result = minimize(objective_function, params, method='L-BFGS-B', \n",
    "                    bounds=bounds, args=k_data)#args传进来的是一个元组\n",
    "    \n",
    "    print(\"Gradient:\", result.jac)\n",
    "    # optimized_h, optimized_U1, optimized_U2 = result.x[0], result.x[1:M+1], result.x[M+1:]\n",
    "    optimized_U1, optimized_U2 = result.x[0:M], result.x[M:]\n",
    "    # print('optimized_h, optimized_U1, optimized_U2',optimized_h, optimized_U1, optimized_U2)\n",
    "\n",
    "    # 获取当前时刻下，在最优的U1、U2下的响应    \n",
    "    u1_k = optimized_U1[0]\n",
    "    u2_k = optimized_U2[0]\n",
    "    u1_k_1 = k_data[5]\n",
    "    u2_k_1 = k_data[7]\n",
    "    y1_k = k_data[9] \n",
    "    y2_k = k_data[11] \n",
    "\n",
    "    y1_pred, y2_pred,noise1 ,noise2= nonlinear_system(y1_k, y2_k, u1_k, u2_k, u1_k_1, u2_k_1)\n",
    "    # print(noise1)\n",
    "    all_pred_noise1.append(noise1)\n",
    "    all_pred_noise2.append(noise2)\n",
    "    # print(\"666666666666\")\n",
    "    # 获取当前时刻下，在最优的U1、U2下的响应\n",
    "    params = np.concatenate((optimized_U1,optimized_U2),axis=0)\n",
    "    mse, k_data2 =my_MPC(k_data=k_data,params=params,M=M,P=P, y1_aim = set_y1[k], y2_aim = set_y2[k]) \n",
    "    all_pred_y1.append(y1_pred)\n",
    "    all_pred_y2.append(y2_pred)\n",
    "    all_pred_u1.append(u1_k)\n",
    "    all_pred_u2.append(u2_k)\n",
    "    k_data2[9]  = y1_pred\n",
    "    k_data2[11] = y2_pred\n",
    "    k_data = k_data2\n",
    "    # 进入下一时刻，更新预测时域、控制时域，即k_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测控制结果可视化\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(set_y1, 'ro-', label='set_y1')\n",
    "plt.plot(np.array(all_pred_y1), 'bo-', label='y1')\n",
    "plt.plot(np.array(all_pred_y1)-np.array(all_pred_noise1), 'go-', label='y1-noise')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "# plt.xlabel('Sample Index')\n",
    "plt.ylabel('y1')\n",
    "# plt.title('Comparison of set_y1 and all_pred_y1')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(set_y2, 'ro-', label='set_y2')\n",
    "plt.plot(np.array(all_pred_y2), 'bo-', label='y2')\n",
    "plt.plot(np.array(all_pred_y2)-np.array(all_pred_noise2), 'go-', label='y2-noise')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "# plt.xlabel('Sample Index')\n",
    "plt.ylabel('y2')\n",
    "# plt.title('Comparison of set_y2 and all_pred_y2')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第一个维度的u1曲线\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(all_pred_u1, 'bo-', label='u1')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "# plt.xlabel('Sample Index')\n",
    "plt.ylabel('u1')\n",
    "# plt.title('Prediction of all_pred_u1')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(all_pred_u2, 'bo-', label='u2')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "# plt.xlabel('Sample Index')\n",
    "plt.ylabel('u2')\n",
    "# plt.title('Prediction of all_pred_u2')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测控制结果可视化\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(set_y1, 'r-', label='set_y1')\n",
    "plt.plot(np.array(all_pred_y1), 'b-', label='all_pred_y1')\n",
    "plt.plot(np.array(all_pred_y1)-np.array(all_pred_noise1), 'g-', label='all_pred_y1-noise')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of set_y1 and all_pred_y1')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(set_y2, 'r-', label='set_y2')\n",
    "plt.plot(np.array(all_pred_y2), 'b-', label='all_pred_y2')\n",
    "plt.plot(np.array(all_pred_y2)-np.array(all_pred_noise2), 'g-', label='all_pred_y2-noise')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of set_y2 and all_pred_y2')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第一个维度的u1曲线\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(all_pred_u1, 'b-', label='all_pred_u1')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Prediction of all_pred_u1')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(all_pred_u2, 'b-', label='all_pred_u2')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Prediction of all_pred_u2')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
